{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "seed = 2**31 - 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# Backpropagation\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will write the backpropagation manually. It is valuable exercise for gaining a deeper understanding of the algorithm. Although in practice, we typically do not implement backpropagation manually, it is crucial to comprehend the process that occurs beneath the surface.   \n",
    "\n",
    "One challenge with backpropagation is that it represents a [leaky abstraction](https://www.wikiwand.com/en/Leaky_abstraction). Understanding of the algorithm can avoid numerous errors and improve the ability to debug issues that may arise."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # names: ...................32,033\n",
      "Total # characters in all names: 196,113\n",
      "['emma', 'olivia', 'ava', 'isabella', 'sophia']\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "with open('./data/names.txt', 'r') as f:\n",
    "    names = f.read().splitlines()\n",
    "print(f'Total # names: {len(names):.>25,}')\n",
    "print(f\"Total # characters in all names: {len(''.join(names)):,}\")\n",
    "print(names[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding and decoding characters**   \n",
    "We define an encoder `ch2ix` and decoder `ix2ch` function that maps a character with a numerical representation (i.e. a unique integer) and vice-versa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder ch2ix:\n",
      " {'.': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n",
      "Decoder ix2ch:\n",
      " {0: '.', 1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z'}\n",
      "E.g. emma: [0, 5, 13, 13, 1, 0]\n",
      "Vocab size: 27\n"
     ]
    }
   ],
   "source": [
    "chars = '.' + string.ascii_lowercase\n",
    "ch2ix = {s: i for i, s in enumerate(chars)}\n",
    "ix2ch = {i: s for s, i in ch2ix.items()}\n",
    "\n",
    "print('Encoder ch2ix:\\n', ch2ix)\n",
    "print('Decoder ix2ch:\\n', ix2ch)\n",
    "print('E.g. emma:', [ch2ix[c] for c in '.emma.'])\n",
    "\n",
    "vocab_size = len(chars)\n",
    "print(f'Vocab size: {vocab_size:,}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Attributes:\n",
    "    names: list of names.\n",
    "    block_size: context length: how many characters do we take to predict the next one?\n",
    "    \"\"\"\n",
    "\n",
    "    names: list[str]\n",
    "    block_size: int = 3\n",
    "    verbose: bool = False\n",
    "    X: Tensor = field(init=False)\n",
    "    Y: Tensor = field(init=False)\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self._make_dataset()\n",
    "\n",
    "    def _make_dataset(self) -> None:\n",
    "        X, Y = [], []\n",
    "        for w in self.names:\n",
    "            if self.verbose:\n",
    "                print(w)\n",
    "            context = [0] * self.block_size\n",
    "            for ch in w + '.':\n",
    "                ix = ch2ix[ch]\n",
    "                X.append(context)\n",
    "                Y.append(ix)\n",
    "                if self.verbose:\n",
    "                    print(''.join(ix2ch[i] for i in context), '--->', ix2ch[ix])\n",
    "                context = context[1:] + [ix]  # crop and append\n",
    "        self.X = torch.tensor(X)\n",
    "        self.Y = torch.tensor(Y)\n",
    "        print(f'X.shape: {self.X.shape}, Y.shape: {self.Y.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: torch.Size([182671, 3]), Y.shape: torch.Size([182671])\n",
      "X.shape: torch.Size([22784, 3]), Y.shape: torch.Size([22784])\n",
      "X.shape: torch.Size([22691, 3]), Y.shape: torch.Size([22691])\n"
     ]
    }
   ],
   "source": [
    "# Create a training, validation and test set\n",
    "block_size = 3\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(names)\n",
    "\n",
    "n1 = int(0.8 * len(names))\n",
    "n2 = int(0.9 * len(names))\n",
    "\n",
    "ds_tr = Dataset(names[:n1], block_size=block_size)\n",
    "Xtr, Ytr = ds_tr.X, ds_tr.Y  # 80%\n",
    "ds_val = Dataset(names[n1:n2], block_size=block_size)\n",
    "Xval, Yval = ds_val.X, ds_val.Y  # 10%\n",
    "ds_te = Dataset(names[n2:], block_size=block_size)\n",
    "Xte, Yte = ds_te.X, ds_te.Y  # 10%"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_gradients(description, manual_grads, autograd_grads):\n",
    "    exact_match = torch.all(manual_grads == autograd_grads.grad).item()\n",
    "    approx_match = torch.allclose(manual_grads, autograd_grads.grad)\n",
    "    max_difference = (manual_grads - autograd_grads.grad).abs().max().item()\n",
    "    print(f'{description:15s} | exact: {str(exact_match):5s} | approximate: {str(approx_match):5s} | maxdiff: {max_difference}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialise a MLP model with 64 hidden units and an character embedding dimension of 10. \n",
    "\n",
    "\n",
    "```{note}\n",
    "Because we have a batch norm layer, we do not need to add a bias term to the linear layers. We define them anyway because it's still interesting to calculate the gradients.\n",
    "```\n",
    "Normally we should initialise the weights and biases as follows:   \n",
    "- gain = 5/3 for tanh   \n",
    "- $W_1: \\large\\frac{5/3}{\\sqrt{\\text{fan}_{\\text{in}}}}$    \n",
    "- $b_1: 0$   \n",
    "- $W_2: \\large\\frac{5/3}{\\sqrt{\\text{fan}_{\\text{in}}}}$   \n",
    "- $b_2: 0$   \n",
    "\n",
    "However, we will initialise the weights and biases in non-standard ways because sometimes initializating with e.g. all zeros could mask an incorrect implementation of the backward pass. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # parameters: 4,137\n"
     ]
    }
   ],
   "source": [
    "n_emb = 10  # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64  # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(seed)  # for reproducibility\n",
    "C = torch.randn((vocab_size, n_emb), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_emb * block_size, n_hidden), generator=g) * (5 / 3) / ((n_emb * block_size) ** 0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bn_gain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bn_bias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bn_gain, bn_bias]\n",
    "n_params = sum(p.nelement() for p in parameters)\n",
    "print(f'Total # parameters: {n_params:,}')\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate a single batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (bs,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]  # batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate a forward pass on the batch**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make the forward pass with the smallest steps possible. This will make it easier to understand the backward pass.\n",
    "\n",
    "Batch norm calculation:\n",
    "- emb_cat is a 32x30 tensor (batch size x sequence length)\n",
    "- $\\textrm{h\\_pre\\_bn} = \\textrm{emb\\_cat} \\cdot W_1 + b_1$\n",
    "- $\\textrm{bn\\_mean\\_i} = \\sum_{i=1}^{32}{h\\_pre\\_bn}_i$\n",
    "- $\\textrm{bn\\_diff} = \\textrm{h\\_pre\\_bn} - \\textrm{bn\\_mean\\_i}$\n",
    "- $\\textrm{bn\\_diff2}= \\textrm{bn\\_diff}^2$\n",
    "- $\\textrm{bn\\_var} = \\sum_{i=1}^{32}\\textrm{bn\\_diff2}$\n",
    "- $\\textrm{bn\\_var\\_inv} = \\frac{1}{\\sqrt{(\\textrm{bn\\_var} + \\epsilon)}}$\n",
    "- $\\textrm{bn\\_raw} = \\textrm{bn\\_diff} * \\textrm{bn\\_var\\_inv}$\n",
    "- $\\textrm{h\\_pre\\_act} = \\textrm{bn\\_gain} * \\textrm{bn\\_raw} + \\textrm{bn\\_bias}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the characters into vectors and concatenate them\n",
    "emb = C[Xb]  # 32 x 3 x 10\n",
    "emb_cat = emb.view(emb.shape[0], -1)  # 32 x 30\n",
    "\n",
    "# Linear layer 1\n",
    "# pre-batch norm\n",
    "h_pre_bn = emb_cat @ W1 + b1  # 32 x 64\n",
    "# batch norm layer\n",
    "bn_mean_i = h_pre_bn.sum(0, keepdim=True) / bs  # 1 x 64 (keepdim=True to keep the 1 x 64 shape otherwise 64)\n",
    "bn_diff = h_pre_bn - bn_mean_i  # 32 x 64\n",
    "bn_diff2 = bn_diff**2  # 32 x 64\n",
    "bn_var = bn_diff2.sum(0, keepdim=True) / (bs - 1)  # 1 x 64  Bessel's correction (dividing by n-1, not n)\n",
    "bn_var_inv = (bn_var + 1e-5) ** -0.5  # 1 x 64\n",
    "bn_raw = bn_diff * bn_var_inv  # 32 x 64 batchnorm raw output\n",
    "h_pre_act = bn_gain * bn_raw + bn_bias  # 32 x 64 hiodden layer pre-activation\n",
    "# non-linearity\n",
    "h = torch.tanh(h_pre_act)  # 32 x 64\n",
    "\n",
    "# Linear layer 2\n",
    "# output layer\n",
    "logits = h @ W2 + b2  # 32 x 28\n",
    "\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values  # 32 x 1\n",
    "norm_logits = logits - logit_maxes  # 32 x 27 subtract max for numerical stability\n",
    "counts = norm_logits.exp()  # 32 x 27\n",
    "counts_sum = counts.sum(1, keepdims=True)  # 32 x 1\n",
    "counts_sum_inv = counts_sum**-1  # 32 x 1\n",
    "probs = counts * counts_sum_inv  # 32 x 27\n",
    "logprobs = probs.log()  # 32 x 27\n",
    "loss = -logprobs[range(bs), Yb].mean()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch backward pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first calculate the backward pass with Pytorch's autograd. This will allow us to compare the results of our manual implementation with the Pytorch implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4002, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [\n",
    "    logprobs,\n",
    "    probs,\n",
    "    counts,\n",
    "    counts_sum,\n",
    "    counts_sum_inv,\n",
    "    norm_logits,\n",
    "    logit_maxes,\n",
    "    logits,\n",
    "    h,\n",
    "    h_pre_act,\n",
    "    bn_raw,\n",
    "    bn_var_inv,\n",
    "    bn_var,\n",
    "    bn_diff2,\n",
    "    bn_diff,\n",
    "    h_pre_bn,\n",
    "    bn_mean_i,\n",
    "    emb_cat,\n",
    "    emb,\n",
    "]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual backward pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross entropy loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now calculate the backward pass of each step manually. We will compare the results with the Pytorch implementation.\n",
    "\n",
    "```{note}\n",
    "The shape of the gradient should be the same as the shape of its parameter\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**logprobs** \n",
    "```python\n",
    "loss = -logprobs[range(bs), Yb].mean()\n",
    "```\n",
    "\n",
    "\n",
    "```python \n",
    "logprobs[range(bs), Yb]\n",
    "``` \n",
    "plucks the `logprob` corresponding to the value of the element of `Yb` for each sample in the batch.\n",
    "\n",
    "\n",
    "The derivative of `loss` with respect to the `logprobs` is 0 everywhere except for the `logprob` corresponding to the value of the elements of `Yb` where it is $-\\large\\frac{1}{bs}$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_logprobs = torch.zeros_like(logprobs)  # 32 x 27\n",
    "d_logprobs[range(bs), Yb] = -1.0 / bs\n",
    "\n",
    "compare_gradients('logprobs', d_logprobs, logprobs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**probs**\n",
    "\n",
    "```python\n",
    "logprobs = probs.log()\n",
    "```\n",
    "All the elements of `probs` are loged element-wise. The derivative of a log is ${\\large\\frac{d}{dx}} log(x) = \\large\\frac{1}{x}$.\n",
    "\n",
    "The derivative of `logprobs` with respect to `probs` is thus (chain rule) ${\\large\\frac{1}{probs}} * \\textrm{d\\_logprobs}$.   \n",
    "\n",
    "\n",
    "Intuitively, if an element of `probs` is close to 1, the network correctly predicts the next character.  The `d_logprobs` is just passed through.  \n",
    "However, when an element of `probs` is small, 1/probs is big and amplifies `d_logprobs`.\n",
    "\n",
    "`probs` and `d_logprobs` are both 32x27 tensors and therfore can be multiplied without broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_probs = (1.0 / probs) * d_logprobs  # 32 x 27\n",
    "\n",
    "compare_gradients('probs', d_probs, probs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_counts_sum_inv**\n",
    "\n",
    "```python\n",
    "probs = counts * counts_sum_inv\n",
    "```\n",
    "\n",
    "\n",
    "---\n",
    "Toy example:   \n",
    "Broadcasting a 3x1 tensor to a 3x3 tensor\n",
    "\n",
    "\\begin{align*}\n",
    "  c &= a * b\\\\\n",
    "  c[3\\text{x}3] &= a[3\\text{x}3] * b[3\\text{x}1]\\\\\n",
    "  \\begin{bmatrix}\n",
    "    c_{11} & c_{12} & c_{13}\\\\\n",
    "    c_{21} & c_{22} & c_{23}\\\\\n",
    "    c_{31} & c_{32} & c_{33}\n",
    "  \\end{bmatrix} &=\n",
    "  \\begin{bmatrix}\n",
    "    a_{11}*b_1 & a_{12}*b_1 & a_{13}*b_1\\\\\n",
    "    a_{21}*b_2 & a_{22}*b_2 & a_{23}*b_2\\\\\n",
    "    a_{31}*b_3 & a_{32}*b_3 & a_{33}*b_3\n",
    "  \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "This is actually 2 operations: first we replicate the 3x1 tensor to a 3x3 tensor and then we multiply the 2 tensors element-wise.   \n",
    "\n",
    "To calculate the derivative of c with respect to b, we first calculate the derivative of a * b with respect to b. This is a.   \n",
    "\n",
    "Then we have to calculate the derivative of the replication of b with respect to b. On the computational graph, b is branched into 3 branches.\n",
    "\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix}\n",
    "    a_{11}*b_1\\\\\n",
    "    a_{21}*b_2\\\\\n",
    "    a_{31}*b_3    \n",
    "  \\end{bmatrix} ,\n",
    "  \\begin{bmatrix}\n",
    "    a_{12}*b_1\\\\\n",
    "    a_{22}*b_2\\\\\n",
    "    a_{32}*b_3    \n",
    "  \\end{bmatrix} \\textrm{and}\n",
    "  \\begin{bmatrix}\n",
    "    a_{13}*b_1\\\\\n",
    "    a_{23}*b_2\\\\\n",
    "    a_{33}*b_3    \n",
    "  \\end{bmatrix} \n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "The derivative is the sum of the derivatives of the 3 branches:\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix}\n",
    "    a_{11} + a_{21} + a_{31}\\\\\n",
    "    a_{21} + a_{22} + a_{32}\\\\\n",
    "    a_{31} + a_{23} + a_{33}    \n",
    "  \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "---\n",
    "`counts` is a 32x27 tensor and `counts_sum_inv` is a 32x1 tensor. `counts_sum_inv` gets broadcasted (replicated 27x) to a 32x27 tensor and then multiplied by `counts`. In the backward pass we have to sum the derivatives of the 27 branches.\n",
    "\n",
    "```{note}\n",
    "In the forward pass, if we sum the tensor or compute its mean, max, etc., we need to replicate it (for broadcasting) in the backward pass. Similarly, if we replicate the tensor in the forward pass, we need to sum it in the backward pass.\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_counts_sum_inv = (counts * d_probs).sum(1, keepdims=True)  # 32 x 1\n",
    "\n",
    "compare_gradients('counts_sum_inv', d_counts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_counts** - branch 1  \n",
    "```python\n",
    "probs = counts * counts_sum_inv\n",
    "```\n",
    "`counts_sum_inv` depends on `counts`. `counts_sum_inv` backpropagates through `counts_sum` and `counts_sum` backpropagates through `counts`. `counts` is a node that is used twice. The two branches are:\n",
    "```python\n",
    "probs = counts * counts_sum_inv\n",
    "```\n",
    "and\n",
    "```python\n",
    "counts_sum = counts.sum(1, keepdims=True)  \n",
    "counts_sum_inv = counts_sum**-1\n",
    "```\n",
    "We have to sum the gradients of the two branches later to get the correct gradient of `counts`.\n",
    "\n",
    "`counts` is a 32x27 tensor `counts_sum_inv` is a 32x1 tensor. `counts_sum_inv` gets broadcasted, not`counts`, so we don't sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_counts = counts_sum_inv * d_probs  # 32 x 27\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_counts_sum**   \n",
    "```python\n",
    "counts_sum_inv = counts_sum**-1\n",
    "```\n",
    "$\\large\\frac{d}{dx}\\frac{1}{x} = -\\frac{1}{x^2}$\n",
    "\n",
    "`counts_sum` and `d_counts_sum_inv` are both 32x1 tensors and can be multiplied without broadcasting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_counts_sum = (-1.0 / counts_sum**2) * d_counts_sum_inv  # 32 x 1\n",
    "\n",
    "compare_gradients('counts_sum', d_counts_sum, counts_sum)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_counts** - branch 2  \n",
    "```python  \n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "```\n",
    "`counts_sum` is the sum of the rows of `counts`. `counts` has shape 32x27 and `counts_sum` has shape 32x1. \n",
    "\n",
    "---\n",
    "Toy example:\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix}\n",
    "    a_{11} & a_{12} & a_{13}\\\\\n",
    "    a_{21} & a_{22} & a_{23}\\\\\n",
    "    a_{31} & a_{32} & a_{33}\n",
    "  \\end{bmatrix} =>\n",
    "  \\begin{bmatrix}\n",
    "    b_1(=a_{11} + a_{12} + a_{13})\\\\\n",
    "    b_2(=a_{21} + a_{22} + a_{23})\\\\\n",
    "    b_3(=a_{31} + a_{32} + a_{33})\n",
    "  \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "We have a 3x3 tensor a and sum the rows to get a 3x1 tensor b. We have the derivative of the loss with respect to b. We want to calculate the derivative of the loss with respect to the elements of a.  \n",
    "b1 only depends on a11, a12 and a13. The derivative of b1 with respect to a11, a12, and a13 is 1. The derivative of b1 with respect to all the other elements of a is 0.  \n",
    "In the chain rule, we multiply the derivative of the loss with respect to b1 with the derivative of b1 with respect to a11, a12 and a13. \n",
    "\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix}\n",
    "    1 & 1 & 1\\\\\n",
    "    1 & 1 & 1\\\\\n",
    "    1 & 1 & 1\n",
    "  \\end{bmatrix} *\n",
    "    \\begin{bmatrix}\n",
    "    b_1\\\\\n",
    "    b_2\\\\\n",
    "    b_3\n",
    "  \\end{bmatrix} =\n",
    "  \\begin{bmatrix}\n",
    "    b_1 & b_1 & b_1\\\\\n",
    "    b_2 & b_2 & b_2\\\\\n",
    "    b_3 & b_3 & b_3\n",
    "  \\end{bmatrix}\n",
    "\\end{align*}\n",
    "---\n",
    "\n",
    "```{note}\n",
    "An addition can be seen as a router of gradients. The gradient comming from above gets routed equally to all the elements that participate in the addition. In this case the derivative of the loss with respect to b1 is routed equally to a11, a12 and a13. \n",
    "```\n",
    "\n",
    "\n",
    "In the backpropagation we need to take the 32x1 tensor `d_counts_sum` and replicate it to form a 32x27 tensor.  We also need to add this `d_counts` gradients to the `d_counts` gradients that from the other branch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_counts += torch.ones_like(counts) * d_counts_sum  # 32 x 27\n",
    "\n",
    "compare_gradients('counts', d_counts, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_norm_logits**   \n",
    "\n",
    "```python\n",
    "counts = norm_logits.exp()\n",
    "```\n",
    "\n",
    "$\\large\\frac{d}{dx}e^x = e^x$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_norm_logits = norm_logits.exp() * d_counts  # 32 x 27 == counts * d_counts\n",
    "\n",
    "compare_gradients('norm_logits', d_norm_logits, norm_logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_logits** - branch 1, **d_logit_maxes** \n",
    "\n",
    "```python\n",
    "norm_logits = logits - logit_maxes \n",
    "```\n",
    "\n",
    "---\n",
    "Toy example:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix}\n",
    "    c_{11} & c_{12} & c_{13}\\\\\n",
    "    c_{21} & c_{22} & _{23}\\\\\n",
    "    c_{31} & c_{32} & _{33}\n",
    "  \\end{bmatrix} =\n",
    "  \\begin{bmatrix}\n",
    "    a_{11} & a_{12} & a_{13}\\\\\n",
    "    a_{21} & a_{22} & a_{23}\\\\\n",
    "    a_{31} & a_{32} & a_{33}\n",
    "  \\end{bmatrix} -\n",
    "  \\begin{bmatrix}\n",
    "    b_1\\\\\n",
    "    b_2\\\\\n",
    "    b_3\n",
    "  \\end{bmatrix} = \n",
    "  \\begin{bmatrix}\n",
    "    a_{11}-b1 & a_{12}-b_1 & a_{13}-b_1\\\\\n",
    "    a_{21}-b2 & a_{22}-b_2 & a_{23}-b_2\\\\\n",
    "    a_{31}-b3 & a_{32}-b_3 & a_{33}-b_3\n",
    "  \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "The broadcasting of b to a is done by replicating b to a 3x3 tensor. This effectively creates 3 branches. To calculate the derivative of c with respect to b, we need to sum the derivatives of the 3 branches. \n",
    "\n",
    "---\n",
    "`norm_logits` is a 32x27 tensor, `logits` is a 32x27 tensor and `logit_maxes` is a 32x1 tensor. \n",
    "`logit_maxes` gets broadcasted so we sum the gradients. `logits` doesn't gets broadcasted so we don't sum the gradients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits_maxes    | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_logits = d_norm_logits.clone()  # 32 x 27\n",
    "d_logits_maxes = (-d_norm_logits).sum(1, keepdims=True)  # 32 x 1\n",
    "\n",
    "compare_gradients('logits_maxes', d_logits_maxes, logit_maxes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We substracted the maximum of the logits from the logits for numerical stability, otherwise the exponentiation of the logits could overflow when a logit is large. This shifting operation has no effect on `probs`.   \n",
    "\n",
    "$\\Large\\frac{e^x}{\\sum_i{e^x_i}} =  \\frac{e^{x+a}}{\\sum_i{e^{x_i+a}}}$    \n",
    "\n",
    "Because subtracting the maximum of the logits from the logits has no effect on `probs` it will also not change `loss`. The gradients of `logits_maxes` should all be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8626e-09],\n",
       "        [ 1.8626e-09],\n",
       "        [ 9.3132e-10],\n",
       "        [ 4.6566e-09],\n",
       "        [ 3.2596e-09],\n",
       "        [ 2.5611e-09],\n",
       "        [ 1.6298e-09],\n",
       "        [ 1.3970e-09],\n",
       "        [-2.0955e-09],\n",
       "        [ 0.0000e+00],\n",
       "        [-1.8626e-09],\n",
       "        [-3.2596e-09],\n",
       "        [ 1.8626e-09],\n",
       "        [ 1.6298e-09],\n",
       "        [ 0.0000e+00],\n",
       "        [-1.1642e-09],\n",
       "        [ 6.9849e-10],\n",
       "        [ 2.3283e-09],\n",
       "        [ 1.3970e-09],\n",
       "        [-2.0955e-09],\n",
       "        [-2.0955e-09],\n",
       "        [-3.2596e-09],\n",
       "        [-9.3132e-10],\n",
       "        [ 1.1642e-09],\n",
       "        [ 1.3970e-09],\n",
       "        [-2.3283e-10],\n",
       "        [-5.8208e-09],\n",
       "        [ 6.9849e-10],\n",
       "        [ 0.0000e+00],\n",
       "        [ 4.6566e-10],\n",
       "        [-4.6566e-10],\n",
       "        [ 0.0000e+00]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_logits_maxes\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_logits** - branch 2\n",
    "\n",
    "```python\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "```\n",
    "`logits.max(1)` returns a tuple of 2 tensors. The first tensor is the maximum values of each row of `logits` and the second tensor is the indices of the maximum values.\n",
    "\n",
    "We have a 32 x 27 tensor. The max of the tensor plucks out the maximum value of each row and returns a 32 x 1 tensor. The derivative should be 1 * d_logit_maxes for the maximum value and 0 for all the other values in the row.  \n",
    "We can calculate the derivative like we did for `logprobs` where we created a 32 x 27 zero-tensor and then populate it with 1 at the indices of the maximum values. Another way is to create a one-hot tensor with a 1 at the indices of the maximum values. \n",
    "\n",
    "Because we are on the second branch, we also need to add the d_logits from the first branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_logits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * d_logits_maxes  # 32 x 27\n",
    "\n",
    "compare_gradients('logits', d_logits, logits)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_h**, **d_W2**, **d_b2**  \n",
    "\n",
    "```python\n",
    "logits = h @ W2 + b2 \n",
    "```\n",
    "---\n",
    "Toy example:\n",
    "\n",
    "\\begin{align*}\n",
    "  d &= a @ b + c\\\\\\\\\n",
    "  \\begin{bmatrix}\n",
    "    d_{11} & d_{12}\\\\\n",
    "    d_{21} & d_{22}\n",
    "  \\end{bmatrix} &=\n",
    "  \\begin{bmatrix}\n",
    "    a_{11} & a_{12}\\\\\n",
    "    a_{21} & a_{22}\n",
    "  \\end{bmatrix} \\cdot\n",
    "  \\begin{bmatrix}\n",
    "      b_{11} & b_{12}\\\\\n",
    "      b_{21} & b_{22}\n",
    "  \\end{bmatrix} +\n",
    "  \\begin{bmatrix}\n",
    "      c_{11} & c_{12}\\\\\n",
    "      c_{21} & c_{22}\n",
    "  \\end{bmatrix}\\\\\\\\\n",
    "  &\\Rightarrow\n",
    "  \\begin{cases}\n",
    "    d_{11} &= a_{11}.b_{11} +a_{12}.b_{21} + c_1\\\\\n",
    "    d_{12} &= a_{11}.b_{12} +a_{12}.b_{22} + c_2\\\\\n",
    "    d_{21} &= a_{21}.b_{11} +a_{22}.b_{21} + c_1\\\\\n",
    "    d_{22} &= a_{21}.b_{12} +a_{22}.b_{22} + c_2\n",
    "  \\end{cases}\\\\\\\\\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\textsf{We can now calculate the derivative of d with respect to a.}&\\\\\n",
    "  \\begin{cases}\n",
    "    \\large\\frac{\\delta L}{\\delta a_{11}} &= {\\large\\frac{\\delta L}{\\delta d_{11}}}.b_{11} + {\\large\\frac{\\delta L}{\\delta d_{12}}}.b_{12}\\\\\\\\\n",
    "    \\large\\frac{\\delta L}{\\delta a_{12}} &= {\\large\\frac{\\delta L}{\\delta d_{11}}}.b_{21} + {\\large\\frac{\\delta L}{\\delta d_{12}}}.b_{22}\\\\\\\\\n",
    "    \\large\\frac{\\delta L}{\\delta a_{21}} &= {\\large\\frac{\\delta L}{\\delta d_{21}}}.b_{11} + {\\large\\frac{\\delta L}{\\delta d_{22}}}.b_{12}\\\\\\\\\n",
    "    \\large\\frac{\\delta L}{\\delta a_{22}} &= {\\large\\frac{\\delta L}{\\delta d_{21}}}.b_{21} + {\\large\\frac{\\delta L}{\\delta d_{22}}}.b_{22} \n",
    "  \\end{cases}\\\\\\\\\n",
    "\n",
    "  \\frac{\\delta L}{\\delta a} =\n",
    "  \\begin{bmatrix}\n",
    "    \\large\\frac{\\delta L}{\\delta a_{11}} & \\large\\frac{\\delta L}{\\delta a_{12}}\\\\\\\\\n",
    "    \\large\\frac{\\delta L}{\\delta a_{21}} & \\large\\frac{\\delta L}{\\delta a_{22}}\n",
    "  \\end{bmatrix} =\n",
    "  \\begin{bmatrix}\n",
    "    \\large\\frac{\\delta L}{\\delta d_{11}} & \\large\\frac{\\delta L}{\\delta d_{12}}\\\\\\\\\n",
    "    \\large\\frac{\\delta L}{\\delta d_{21}} & \\large\\frac{\\delta L}{\\delta d_{22}}\n",
    "  \\end{bmatrix} \\cdot\n",
    "  \\begin{bmatrix}\n",
    "    b_{11} & b_{21}\\\\\n",
    "    b_{12} & b_{22}\n",
    "  \\end{bmatrix} &=\n",
    "\n",
    "  \\begin{bmatrix}\n",
    "    \\large\\frac{\\delta L}{\\delta d_{11}} & \\large\\frac{\\delta L}{\\delta d_{12}}\\\\\\\\\n",
    "    \\large\\frac{\\delta L}{\\delta d_{21}} & \\large\\frac{\\delta L}{\\delta d_{22}}\n",
    "  \\end{bmatrix} \\cdot\n",
    "  \\begin{bmatrix}\n",
    "    b_{11} & b_{12}\\\\\n",
    "    b_{21} & b_{22}\n",
    "  \\end{bmatrix}^T =\n",
    "\n",
    "  \\frac{\\delta L}{\\delta d} \\cdot b^T\\\\\\\\\n",
    "\n",
    "  \\textsf{Similarly, we can calculate the derivative of d with respect to b.}\\\\\n",
    "  \\frac{\\delta L}{\\delta b} = a^T \\cdot \\frac{\\delta L}{\\delta d}\\\\\\\\\n",
    "\n",
    "  \\textsf{And the derivative of d with respect to c.}\\\\\n",
    "  \\begin{cases}\n",
    "    \\large\\frac{\\delta L}{\\delta c_1} &= {\\large\\frac{\\delta L}{\\delta d_{11}}}.1 + {\\large\\frac{\\delta L}{\\delta d_{21}}}.1\\\\\\\\\n",
    "    \\large\\frac{\\delta L}{\\delta c_2} &= {\\large\\frac{\\delta L}{\\delta d_{12}}}.1 + {\\large\\frac{\\delta L}{\\delta d_{22}}}.1\n",
    "  \\end{cases}\\\\\\\\\n",
    "  \\frac{\\delta L}{\\delta c} = \\frac{\\delta L}{\\delta d}\\textsf{.sum(axis=0)}\\\\\\\\\n",
    "\n",
    "\\end{align*}\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "`h` is a 32 x 64 tensor, `W2` is a 64 x 27 tensor and `b2` is 27d vector. The bias `b2` is broadcasted to a 32 x 27 tensor (`h @ W2`). Internally, the broadcasting is done by casting the 27d vector to a 1 x 27 tensor and then replicating it vertically to a 32 x 27 tensor. \n",
    "\n",
    "```{note}\n",
    "It's not realy necessary to remember the formula's for the derivatives of the linear transformation. The dimensions of the tensors will tell how to calculate the derivatives.\n",
    "\n",
    "Example:\n",
    "To calculate `d_h`. The shape of `d_h` is equal to the shape of `h`. It's 32 x 64. We also know that `d_h` should be some matrix multiplication of `d_logits` and `W2`. The shape of `d_logits` is 32 x 27 and the shape of `W2` is 64 x 27. So we can conclude that `d_h = d_logits @ W2.T`.  \n",
    "\n",
    "The shape of `d_W2` is equal to the shape of `W2`. It's 64 x 27. We also know that `d_W2` should be some matrix multiplication of `h.T` and `d_logits`. The shape of `h.T` is 64 x 32 and the shape of `d_logits` is 32 x 27. So we can conclude that `d_W2 = h.T @ d_logits`.\n",
    "\n",
    "The shape of `d_b2` is equal to the shape of `b2`. It's 27. We also know that `d_b2` should be the sum of `d_logits` along axis 0. The shape of `d_logits` is 32 x 27. So we can conclude that `d_b2 = d_logits.sum(axis=0)`.\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "d_h = d_logits @ W2.T  # 32 x 64\n",
    "d_W2 = h.T @ d_logits  # 64 x 27\n",
    "d_b2 = d_logits.sum(0, keepdims=True)  # 1 x 27\n",
    "\n",
    "compare_gradients('h', d_h, h)\n",
    "compare_gradients('W2', d_W2, W2)\n",
    "compare_gradients('b2', d_b2, b2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Layer 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Non-linearity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_h_pre_act**   \n",
    "\n",
    "```python\n",
    "h = torch.tanh(h_pre_act)\n",
    "```\n",
    "\n",
    "${\\large\\frac{d}{dx}}\\text{tanh}(x) = 1 - \\text{tanh}^2(x)$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pre_act       | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "d_h_pre_act = (1.0 - h**2) * d_h  # 32 x 64\n",
    "\n",
    "compare_gradients('h_pre_act', d_h_pre_act, h_pre_act)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Batch norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_bn_gain**, **d_bn_raw**, **d_bn_bias**\n",
    "\n",
    "```python\n",
    "h_pre_act = bn_gain * bn_raw + bn_bias\n",
    "```\n",
    "`bn_gain` and `bn_bias` are 1 x 64 tensors. `bn_raw` and `h_pre_act` are 32 x 64 tensors.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_gain         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "bn_raw          | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "bn_bias         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "d_bn_gain = (bn_raw * d_h_pre_act).sum(0, keepdims=True)  # 1 x 64\n",
    "d_bn_raw = bn_gain * d_h_pre_act  # 32 x 64\n",
    "d_bn_bias = d_h_pre_act.sum(0, keepdims=True)  # 1 x 64\n",
    "\n",
    "compare_gradients('bn_gain', d_bn_gain, bn_gain)\n",
    "compare_gradients('bn_raw', d_bn_raw, bn_raw)\n",
    "compare_gradients('bn_bias', d_bn_bias, bn_bias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_bn_diff** - branch 1, **d_bn_var_inv**\n",
    "\n",
    "```python\n",
    "bn_raw = bn_diff * bn_var_inv\n",
    "```\n",
    "`bn_diff` and `bn_raw` are 32 x 64 tensors, `bn_var_inv` is a 1 x 64 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_var_inv      | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n"
     ]
    }
   ],
   "source": [
    "d_bn_diff = bn_var_inv * d_bn_raw  # 32 x 64\n",
    "d_bn_var_inv = (bn_diff * d_bn_raw).sum(0, keepdims=True)  # 1 x 64\n",
    "\n",
    "compare_gradients('bn_var_inv', d_bn_var_inv, bn_var_inv)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_bn_var**\n",
    "    \n",
    "```python\n",
    "bn_var_inv = (bn_var + 1e-5) ** -0.5 \n",
    "```\n",
    "$\\large\\frac{d}{dx}\\frac{1}{\\sqrt(x)} = -\\frac{1}{2x^{3/2}}$\n",
    "\n",
    "`bn_var_inv` and `bn_var` are 1 x 64 tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_var          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "d_bn_var = -0.5 * ((bn_var + 1e-5) ** (-3 / 2)) * d_bn_var_inv  # 1 x 64\n",
    "\n",
    "compare_gradients('bn_var', d_bn_var, bn_var)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_bn_diff2**\n",
    "    \n",
    "```python\n",
    "bn_var = bn_diff2.sum(0, keepdim=True) / (bs - 1)\n",
    "```\n",
    "\n",
    "---\n",
    "Toy example:\n",
    "\n",
    "\\begin{align*}\n",
    "  \\begin{bmatrix}\n",
    "    a_{11} & a_{12}\\\\\n",
    "    a_{21} & a_{22}\n",
    "  \\end{bmatrix} ->\n",
    "  \\begin{bmatrix}\n",
    "    b_1 & b_2\n",
    "  \\end{bmatrix} =\n",
    "  \\begin{bmatrix}\n",
    "    (a_{11} + a_{12})/(bs-1) &  (a_{21} + a_{22})/(bs-1)\n",
    "  \\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "---\n",
    "\n",
    "`bn_diff2` is a 32 x 64 tensor, `bn_var` is a 1 x 64 tensor.\n",
    "The tensor `bn_diff2` is summed in the forward pass, therefore we have to replicate the gradients in the backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_diff2        | exact: False | approximate: True  | maxdiff: 2.9103830456733704e-11\n"
     ]
    }
   ],
   "source": [
    "d_bn_diff2 = torch.ones_like(bn_diff2) / (bs - 1) * d_bn_var  # 1 x 64\n",
    "\n",
    "compare_gradients('bn_diff2', d_bn_diff2, bn_diff2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_bn_diff** - branch 2\n",
    "\n",
    "```python\n",
    "bn_diff2 = bn_diff**2\n",
    "```\n",
    "${\\large\\frac{d}{dx}}x^2 = 2x$\n",
    "\n",
    "`bn_diff2` and `bn_diff` are 32 x 64 tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_diff         | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "d_bn_diff += 2.0 * bn_diff * d_bn_diff2  # 32 x 64\n",
    "\n",
    "compare_gradients('bn_diff', d_bn_diff, bn_diff)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "bn_diff = h_pre_bn - bn_mean_i\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_h_pre_bn** - branch 1, **d_bn_mean_i**\n",
    "\n",
    "```python\n",
    "bn_diff = h_pre_bn - bn_mean_i\n",
    "```\n",
    "`bn_diff` and `h_pre_bn` are 32 x 64 tensors. `bn_mean_i` is a 1 x 64 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn_mean_i       | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n"
     ]
    }
   ],
   "source": [
    "d_h_pre_bn = d_bn_diff.clone()  # 32 x 64\n",
    "d_bn_mean_i = -d_bn_diff.sum(0, keepdims=True)  # 1 x 64\n",
    "\n",
    "compare_gradients('bn_mean_i', d_bn_mean_i, bn_mean_i)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_h_pre_bn** - branch 2 \n",
    "```python\n",
    "bn_mean_i = h_pre_bn.sum(0, keepdim=True) / bs \n",
    "```\n",
    "`bn_mean_i` is a 1 x 64 tensor, `h_pre_bn` is a 32 x 64 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pre_bn        | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n"
     ]
    }
   ],
   "source": [
    "d_h_pre_bn += torch.ones_like(h_pre_bn) / bs * d_bn_mean_i  # 32 x 64\n",
    "\n",
    "compare_gradients('h_pre_bn', d_h_pre_bn, h_pre_bn)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pre-batch norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_emb_cat**, **d_W1**, **d_b1**\n",
    "\n",
    "```python\n",
    "h_pre_bn = emb_cat @ W1 + b1\n",
    "```\n",
    "`h_pre_bn` and `emb_cat` are 32 x 64 tensors, `W1` is a 30 x 64 tensor and `b1` is a 64d vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_cat         | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n",
      "W1              | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "b1              | exact: False | approximate: True  | maxdiff: 2.7939677238464355e-09\n"
     ]
    }
   ],
   "source": [
    "d_emb_cat = d_h_pre_bn @ W1.T  # 32 x 30\n",
    "d_W1 = emb_cat.T @ d_h_pre_bn  # 30 x 64\n",
    "d_b1 = d_h_pre_bn.sum(0)  # 64\n",
    "\n",
    "compare_gradients('emb_cat', d_emb_cat, emb_cat)\n",
    "compare_gradients('W1', d_W1, W1)\n",
    "compare_gradients('b1', d_b1, b1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_emb**\n",
    "\n",
    "```python\n",
    "emb_cat = emb.view(emb.shape[0], -1)\n",
    "```\n",
    "`emb_cat` is a 32 x 30 tensor, `emb` is a 32 x 3 x 10 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb             | exact: False | approximate: True  | maxdiff: 1.862645149230957e-09\n"
     ]
    }
   ],
   "source": [
    "d_emb = d_emb_cat.view(emb.shape)  # 32 x 3 x 10\n",
    "\n",
    "compare_gradients('emb', d_emb, emb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d_C**\n",
    "\n",
    "```python\n",
    "emb = C[Xb]\n",
    "```\n",
    "`emb` is a 32 x 3 x 10 tensor, `C` is a 27 x 10 tensor and `Xb` is a 32 x 3 tensor.\n",
    "\n",
    "Each element of `Xb` a character index. Each character index is used to select a row (10d vector) from `C`.  \n",
    "We can calculate the backward pass in different ways.   \n",
    "- Naive: we first create a zero tensor `d_C` with the same shape as `C` (27 x 10). Then we loop over the 32 samples from `Xb`. For each sample, we loop over the 3 character indices. For each character index, we add the corresponding 10d vector from `d_emb` to the corresponding row in `d_C`.   \n",
    "\n",
    "- Vectorised 1: we first transform each element of `Xb` into a 27d one-hot vector. `Xb_1_hot` is then a 32 x 3 x 27 tensor with 32 samples, each having 3 one-hot vectors. We then reshape `Xb_1_hot` into a (32x3) x 27 tensor and `d_emb` into a (32x3) x 10 tensor. Then `d_C = Xb_1_hot @ d_emb`, which is a 27 x 10 tensor.\n",
    "\n",
    "- Vectorised 2: We can take the dot product of 'Xb_1_hot' and 'd_emb' using [torch.tensordot](https://pytorch.org/docs/stable/generated/torch.tensordot.html). \n",
    "\n",
    "- Vectorised 3: We can use [torch.einsum](https://pytorch.org/docs/stable/generated/torch.einsum.html).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Naive implementation 1\n",
    "d_C = torch.zeros_like(C)  # 27 x 10\n",
    "for i in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[i, j]\n",
    "        d_C[ix] += d_emb[i, j]\n",
    "\n",
    "compare_gradients('C', d_C, C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Vectorized implementation 1\n",
    "one_hot_Xb = F.one_hot(Xb, 27).view((-1, 27)).float()  # 32 x 3 x 27\n",
    "d_C = one_hot_Xb.T @ d_emb.view(-1, 10)  # 27 x 10\n",
    "\n",
    "compare_gradients('C', d_C, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Vectorized implementation 2\n",
    "Xb_1hot = F.one_hot(Xb, vocab_size).float()  # 32 x 3 x 27\n",
    "d_C = torch.tensordot(Xb_1hot, d_emb, dims=([0, 1], [0, 1]))  # type: ignore 27 x 10\n",
    "\n",
    "compare_gradients('C', d_C, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: False | approximate: True  | maxdiff: 7.450580596923828e-09\n"
     ]
    }
   ],
   "source": [
    "# Vectorized implementation 3\n",
    "Xb_1hot = F.one_hot(Xb, vocab_size).float()  # 32 x 3 x 27\n",
    "d_C = torch.einsum('ijk,ijl->kl', Xb_1hot, d_emb)  #  27 x 10\n",
    "\n",
    "compare_gradients('C', d_C, C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation through cross entropy loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections we calculated the cross entropy loss in very small atomic steps and we backpropagated through each step.\n",
    "\n",
    "\n",
    "```python\n",
    "# Cross entropy loss\n",
    "logit_maxes = logits.max(1, keepdim=True).values  \n",
    "norm_logits = logits - logit_maxes \n",
    "counts = norm_logits.exp()  \n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1  \n",
    "probs = counts * counts_sum_inv  \n",
    "logprobs = probs.log()  \n",
    "loss = -logprobs[range(bs), Yb].mean()\n",
    "```\n",
    "In this section we will calculate the cross entropy loss in one step by using [F.cross_entropy](https://pytorch.org/docs/stable/generated/torch.nn.functional.cross_entropy.html) and manually backpropagate through it. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_fast: 3.4002, loss: 3.4002, diff: 0.0000\n"
     ]
    }
   ],
   "source": [
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(f\"loss_fast: {loss_fast.item():.4f}, loss: {loss.item():.4f}, diff: {(loss_fast - loss).item():.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loss_fast` is much faster thant the previous `loss`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115 s  627 ns per loop (mean  std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "logit_maxes = logits.max(1, keepdim=True).values  \n",
    "norm_logits = logits - logit_maxes \n",
    "counts = norm_logits.exp()  \n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1  \n",
    "probs = counts * counts_sum_inv  \n",
    "logprobs = probs.log()  \n",
    "loss = -logprobs[range(bs), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.1 s  687 ns per loop (mean  std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "F.cross_entropy(logits, Yb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will derive the mathematical expressions for calculatind `d_logits` in one step.\n",
    "\n",
    "```python\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "```\n",
    "\n",
    "\n",
    "![cross_entropy_diag](./media/cross_entropy_diag.png)\n",
    "\n",
    "\n",
    "For a single sample, the cross entropy loss is calculated as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "loss &= -log (p_y)\\\\\n",
    "p_i &= \\frac{e^{l_i}}{\\sum_j e^{l_j}}\\\\\n",
    "\\Rightarrow loss &= -log\\frac{e^{l_y}}{\\sum_j e^{l_j}}\n",
    "\\end{align*}\n",
    "where $p$ is a vector of all probablilties, $p_y$ are the probabilities of the label (character) $y$, $p_i$ are the probabilities of the $i$-th sample and $l_i$ the logit of the $i$-th sample.\n",
    "\n",
    "The derivative of the cross entropy loss with respect to the $i$-th logit is: \n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{d}{dl_i}loss = \\frac{d}{dl_i}(-log\\frac{e^{l_y}}{\\sum_j e^{l_j}})\\\\\n",
    "\\end{align*}\n",
    "using ${\\large\\frac{d}{dx}}log(x) =\\large\\frac{1}{x}$  \n",
    "\\begin{align*}\n",
    "& = -\\frac{\\sum_j e^{l_j}}{e^{l_y}}\\frac{d}{dl_i}(\\frac{e^{l_y}}{\\sum_j e^{l_j}}) \\\\\n",
    "& = -\\frac{\\sum_j{e^{l_j}}}{e^{l_y}} {\\left[\\frac{e^{l_y}}{\\sum_j e^{l_j}} -\\frac{e^{l_y}e^{l_i}}{(\\sum_j e^{l_j})^2} \\right]}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "if $i \\neq y$:\n",
    "\n",
    "\\begin{align*}\n",
    "& =\\frac{\\sum_j{e^{l_j}}}{e^{l_y}} {\\left[0 + \\frac{e^{l_y}e^{l_i}}{(\\sum_j{e^{l_j}})^2}  \\right]}\\\\\n",
    "& =\\frac{e^{l_i}}{\\sum_j{e^{l_j}}}\\\\\n",
    "& =p_i\n",
    "\\end{align*}\n",
    "\n",
    "if $i = y$:\n",
    "\n",
    "\\begin{align*}\n",
    "& = -{\\left[ 1-\\frac{e^{l_i}}{\\sum_j{e^{l_j}}} \\right]}\\\\\n",
    "& = \\frac{e^{l_i}}{\\sum_j{e^{l_j}}} - 1\\\\\n",
    "& = p_i - 1\n",
    "\n",
    "\\end{align*}\n",
    "\n",
    "The gradient is either the softmax ($p_i$) or the softmax minus 1 ($p_i-1$) depending on whether the logit .   \n",
    "This is the gradient of a single sample $i$. The loss of a batch is the average of the losses of all samples in the batch. We have to backpropagate through the average as well. The gradient of the average is $\\large\\frac{1}{bs}$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 5.820766091346741e-09\n"
     ]
    }
   ],
   "source": [
    "d_logits = F.softmax(logits, dim=1)  # 32 x 27\n",
    "# substract 1 from the correct class\n",
    "d_logits[range(bs), Yb] -= 1.0\n",
    "# backprop through averaging\n",
    "d_logits /= bs\n",
    "\n",
    "compare_gradients('logits', d_logits, logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intuition of cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAGzCAYAAABJmJyRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABKrklEQVR4nO3dfVhUZf4/8DdPw4M4gygwkKiYJlipGyqylamw4sO2utL30uL6rhrJpQtuim3pbqU9fdnswbJMt63V2qTM7WnTlkJQ/FaIRpGrEqVLoeLgA8sMIA+DnN8ffplfIw+eD8yR8fR+Xddcysxn7rnPmcN8uO+5z+d4KIqigIiIiFTz7O0OEBERXW2YPImIiISYPImIiISYPImIiISYPImIiISYPImIiISYPImIiISYPImIiISYPImIiISYPMntrVmzBh4eHprFd8eePXvg4eGBPXv2aPo6ROSemDyJXCQ7OxvPPfdcb3eDiK4A797uANHVaOLEiWhoaIDBYHDcl52djUOHDmHZsmW91zEiuiKYPIm6wdPTE35+fr3dDSLqJZy2Jbfy6aefYty4cfDz88O1116LP//5zy5pt6WlBY899hiuvfZa+Pr6YsiQIfjDH/6ApqYmp7jW1lasWbMGERERCAgIwOTJk3HkyBEMGTIECxYscMRd+p3npEmTsHPnTvzwww/w8PCAh4cHhgwZ4oh/4YUXcP311yMgIAD9+vXD2LFjkZ2d7ZJtI6IrjyNPchv/+te/MHXqVISEhGDNmjVoaWnB6tWrERYW1uO277nnHrz22mu44447sGLFChQVFSErKwulpaV47733HHGrVq3C2rVrcfvttyMpKQlff/01kpKS0NjY2GX7f/zjH2G1WnHixAmsW7cOABAYGAgA+Mtf/oLf/e53uOOOO3DvvfeisbERBw8eRFFREe66664ebxsR9QKFyE3Mnj1b8fPzU3744QfHfUeOHFG8vLwUyaG6evVqp/iSkhIFgHLPPfc4xd13330KACU/P19RFEWxWCyKt7e3Mnv2bKe4NWvWKACU+fPnO+7bvXu3AkDZvXu3476ZM2cqgwcPbtefWbNmKddff73q/hOR++O0LbmFCxcu4OOPP8bs2bMxaNAgx/0xMTFISkrqUdsfffQRACAzM9Pp/hUrVgAAdu7cCQDIy8tDS0sLfvvb3zrFLV26tEevHxQUhBMnTuDAgQM9aoeI3AeTJ7mFM2fOoKGhAcOHD2/32IgRI3rU9g8//ABPT08MGzbM6X6z2YygoCD88MMPjjgA7eKCg4PRr1+/br/+Aw88gMDAQIwfPx7Dhw9Heno6Pvvss263R0S9j8mTfjK0LpzQmZiYGJSVleGtt97CLbfcgnfeeQe33HILVq9e3Sv9IaKeY/IktxASEgJ/f39899137R4rKyvrUduDBw9Ga2tru7arqqpQU1ODwYMHO+IA4OjRo05x586dw3/+85/Lvk5XyblPnz6YO3cuNm/ejIqKCsycORNPPPHEZRciEZF7YvIkt+Dl5YWkpCS8//77qKiocNxfWlqKjz/+uEdtz5gxAwDaVf959tlnAQAzZ84EACQkJMDb2xsbN250invxxRdVvU6fPn1gtVrb3X/u3Dmnnw0GA0aOHAlFUWC321W1TUTuhaeqkNt45JFHkJOTg1tvvRW//e1v0dLS4jg/8uDBg91ud/To0Zg/fz5efvll1NTU4LbbbsP+/fvx2muvYfbs2Zg8eTIAICwsDPfeey+eeeYZ/OpXv8K0adPw9ddf45///CcGDBhw2Wnf2NhYbNu2DZmZmRg3bhwCAwNx++23Y+rUqTCbzbj55psRFhaG0tJSvPjii5g5cyb69u3b7e0iol7U28t9iX6soKBAiY2NVQwGgzJ06FBl06ZN7U49uZyO4u12u/LII48oUVFRio+PjxIZGamsWrVKaWxsdIpraWlRHnroIcVsNiv+/v7KlClTlNLSUqV///7K4sWLHXEdnapSV1en3HXXXUpQUJACwHHayp///Gdl4sSJSv/+/RVfX1/l2muvVX7/+98rVqtVvoOIyC14KIqi9G76JnJvNTU16NevHx5//HH88Y9/7O3uEJEb4HeeRD/S0NDQ7r6270onTZp0ZTtDRG6L33nSVcNqtXaY3H7MbDb36DW2bduGLVu2YMaMGQgMDMSnn36KN998E1OnTsXNN9/co7aJSD+YPOmqce+99+K1117rMqan30KMGjUK3t7eWLt2LWw2m2MR0eOPP96jdolIX/idJ101jhw5gsrKyi5jEhMTr1BviOinjMmTiIhIiAuGiIiIhNzuO8/W1lZUVlaib9++vVaLlIhIC4qioLa2FhEREfD01G7s0tjYiObm5h63YzAY4Ofn54Ie6Y/bJc/KykpERkb2djeIiDRz/PhxDBw4UJO2GxsbERUVBYvF0uO2zGYzysvLmUA74HbJs61cWXFxMQIDA13evpeXlyh+1KhRqmOlJeQkXzcbDAZR297e6t/aCxcuiNq+3OkiPSGdbZD89W4ymURtX1qTtiutra2itqXHoYR0GUN4eLjqWDUF8n+spaVFdax0JCY5bqX7xNfXV3VsU1OT6ti6ujrcdNNNmpZlbG5uhsViQUVFBYxGY7fbsdlsGDRoEJqbm5k8O6BZ8tywYQOeeuopWCwWjB49Gi+88ALGjx9/2ee1fXgGBgZqcoBJP7QkH+bS/kp+oSW/zIC2yVPStpSWyVP6QSKZ9rqak6dkv0iPFUnhe3dKnpJk0Z0r41yJr6SMRmOPkid1TZNJ97bi2KtXr8aXX36J0aNHIykpCadPn9bi5YiI6BKKovT4Rp3TJHk+++yzWLRoERYuXIiRI0di06ZNCAgIwF//+td2sU1NTbDZbE43IiLqGSZPbbk8eTY3N6O4uNjpZHVPT08kJiaisLCwXXxWVhZMJpPjxsVCREQ9x+SpLZcnz7Nnz+LChQsICwtzuj8sLKzD1V+rVq2C1Wp13I4fP+7qLhEREblUr6+29fX1FS+GISKirvV09MiRZ9dcnjwHDBgALy8vVFVVOd1fVVXV4yteEBGROkye2nL5tK3BYEBsbCzy8vIc97W2tiIvLw/x8fGufjkiIqIrTpNp28zMTMyfPx9jx47F+PHj8dxzz6G+vh4LFy7U4uWIiOgSHHlqS5PkOXfuXJw5cwYPP/wwLBYLxowZg5ycnHaLiLri4eGh+kRiyQnq0hP8v/32W9WxPj4+orYlJ1dLT6qWnJyuZfUVQFZsQMt6n1arVRQv2efDhg0TtX327FnVsVpWdALQ7iuWrkjfH0kxCGkFKMl549KiFFoVd9Dy+L4Uk6e2NFswlJGRgYyMDK2aJyIi6jW9vtqWiIhcjyNPbTF5EhHpEJOntngxbCIiIiGOPImIdIgjT20xeRIR6RCTp7aYPImIdIjJU1v8zpOIiEiII08iIh3iyFNbTJ5ERDrE5Kktt02eMTExqsujdXSd0M5Iy2P17dtXday0jJqknJ+klJ+07aamJlHb0lJnWpYkk/ZFQtLviooKUdv19fWqY6UfYtJ9IilZaTAYRG3X1dWpjpWULASAfv36adIPIjXcNnkSEVH3ceSpLSZPIiIdYvLUFlfbEhERCXHkSUSkQxx5aovJk4hIp5gAtcNpWyIiIiGOPImIdIjTttpi8iQi0iEmT20xeRIR6RCTp7b4nScREZEQR55ERDrEkae23DZ5HjlyRHVd2ZaWFtXtSg8ISU1ZaU3R1tZWzdqW7BNJbVNAvg8lfZHU5JX2JTg4WNS2r6+v6tiTJ0+K2pa8nxcuXBC1Ld2Hzc3NqmOltW0l74+0bWlNZgnJ76YkVvpe9gSTp7Y4bUtERCTktiNPIiLqPo48tcXkSUSkQ0ye2uK0LRERucyGDRswZMgQ+Pn5IS4uDvv37+8yfvv27YiOjoafnx9uvPFGfPTRR06PK4qChx9+GOHh4fD390diYiK+++47p5jq6mqkpKTAaDQiKCgIqampml/DlcmTiEiH2kaePblJbdu2DZmZmVi9ejW+/PJLjB49GklJSTh9+nSH8Z9//jnuvPNOpKam4quvvsLs2bMxe/ZsHDp0yBGzdu1arF+/Hps2bUJRURH69OmDpKQkp8WcKSkpOHz4MHJzc7Fjxw7s3bsXaWlp8p0m4KG42djcZrPBZDKhrKxM9WpbT0/1fwNouWpV2rZk10u2EZCtAPTw8BC17U6rbSV9d6fVtpL3U7pCU9JvQLba1mQyido+d+6c6lhpvyW/b3a7XdS2Vqtta2trMWLECFitVhiNRlGf1Gr7DJWcsdCR2tpajBw5UtTXuLg4jBs3Di+++CKAi/smMjISS5cuxcqVK9vFz507F/X19dixY4fjvgkTJmDMmDHYtGkTFEVBREQEVqxYgfvuuw8AYLVaERYWhi1btmDevHkoLS3FyJEjceDAAYwdOxYAkJOTgxkzZuDEiROIiIjo9j7oCkeeRETUKZvN5nTr7BSh5uZmFBcXIzEx0XGfp6cnEhMTUVhY2OFzCgsLneIBICkpyRFfXl4Oi8XiFGMymRAXF+eIKSwsRFBQkCNxAkBiYiI8PT1RVFTUvY1WgcmTiEiHXDVtGxkZCZPJ5LhlZWV1+Hpnz57FhQsXEBYW5nR/WFgYLBZLh8+xWCxdxrf9e7mY0NBQp8e9vb0RHBzc6eu6AlfbEhHpkKtW2x4/ftxp2lY6va5XHHkSEemQq0aeRqPR6dZZ8hwwYAC8vLxQVVXldH9VVRXMZnOHzzGbzV3Gt/17uZhLFyS1tLSgurq609d1BbcdeXp4eKheDCL5S0hSbg+AaOefOnVK1Ha/fv1Ux1qtVlHb0sVLEpIFQICsL9K2JQuGLv0FdGVfJItuANk+kS7oOn/+vCh+wIABqmPPnj0raluyAEy6D/v3769Z25J9KFn8JV34dzUxGAyIjY1FXl4eZs+eDeDigqG8vDxkZGR0+Jz4+Hjk5eVh2bJljvtyc3MRHx8PAIiKioLZbEZeXh7GjBkD4OJ3sEVFRViyZImjjZqaGhQXFyM2NhYAkJ+fj9bWVsTFxWmzsXDj5ElERN3XG0USMjMzMX/+fIwdOxbjx4/Hc889h/r6eixcuBAA8Jvf/AbXXHON43vTe++9F7fddhueeeYZzJw5E2+99Ra++OILvPzyywAu/uG4bNkyPP744xg+fDiioqLw0EMPISIiwpGgY2JiMG3aNCxatAibNm2C3W5HRkYG5s2bp9lKW4DJk4hIl3ojec6dOxdnzpzBww8/DIvFgjFjxiAnJ8ex4KeiosJp9P3zn/8c2dnZePDBB/GHP/wBw4cPx/vvv48bbrjBEXP//fejvr4eaWlpqKmpwS233IKcnBz4+fk5YrZu3YqMjAwkJCTA09MTycnJWL9+fbe3XQ23Pc/z22+/VX2O0o934uVw2rbnpOfMSaaqJOfMAbIpTemhLvmr9fjx46K2tZy2le5Dd5m2lU7Zu8u0reS4qq2txfDhw6/IeZ5ff/11j8/zHD16tKZ9vZpx5ElEpEOsbastJk8iIh1i8tSWfpd+ERERaYQjTyIiHeLIU1tMnkREOsUEqB1O2xIREQlx5ElEpEOcttUWkycRkQ4xeWrLbZOnwWBQXbNWy4tKd3YF9I74+/uL2q6rq1MdKz2Qvb3Vv7XSE8ilJ+336dNHdaxknwCy91N6Ev6ZM2dUx0r3iWSfSwteXHPNNaJ4yQWrpQUYJMehVHV1tepY6UXWJceVlvV7e4LJU1v8zpOIiEjI5clzzZo1jiuitN2io6Nd/TJERNQFV12SjDqmyZzK9ddfj127dv3/F9Fw6oaIiNrjtK22NMlq3t7eml6ElIiIqDdp8p3nd999h4iICAwdOhQpKSmoqKjoNLapqQk2m83pRkREPcNpW225PHnGxcVhy5YtyMnJwcaNG1FeXo5bb70VtbW1HcZnZWXBZDI5bpGRka7uEhHRTw6Tp7ZcnjynT5+O//qv/8KoUaOQlJSEjz76CDU1NXj77bc7jF+1ahWsVqvjJr0uIhER0ZWm+UqeoKAgXHfddTh69GiHj/v6+qo+n5OIiNThgiFtaX6eZ11dHY4dO4bw8HCtX4qIiP4Pp2215fLked9996GgoADff/89Pv/8c/z617+Gl5cX7rzzTle/FBERUa9w+bTtiRMncOedd+LcuXMICQnBLbfcgn379iEkJETUTnNzM5qamlTFSkqG+fn5ifoxYMAA1bGSMmcAYLfbVccGBASI2pbsE63Pw5WU3JOWT5SQlmiTvD8Gg0HUdt++fVXHNjQ0iNq2WCyieLW/ZwDEX7FIjsN+/fqJ2paUzpSWZpQch5L9x/J8+uHyT8233nrL1U0SEZEQk6e2WPqHiEiHmDy1xcLwREREQhx5EhHpEEee2mLyJCLSISZPbXHaloiISIgjTyIiHeLIU1tMnkREOsTkqS1O2xIREQlx5ElEpEMceWqLyZOISKeYALXjtsmzf//+MBqNqmI7u9B2R6S1Ja1Wq+pYk8kkavvs2bOqYyX1MwEgMDBQdWxNTY2obQ8PD1G8pHautG1pzVIJyQePtB+S41Baj7mxsVEU36dPH83aluyX6upqUduSOrtaHleS+r2SWHJvbps8iYio+zhtqy0mTyIiHWLy1BaTJxGRDjF5aounqhAREQlx5ElEpEMceWqLyZOISIeYPLXFaVsiIiIhjjyJiHSII09tMXkSEekQk6e2OG1LREQk5LYjz3PnzqkuYSYpeSUtdSYp/Xfu3DlR25JSZwEBAaK2JeX8pPtESlKKztNT9vecJF5aok3yl7ekBCEgKy3X0NAganvIkCGi+IqKCtWx0vfHy8tLday0vOXp06c16Qcg206tYnvK3Uee1dXVWLp0KT788EN4enoiOTkZzz//fJelRRsbG7FixQq89dZbaGpqQlJSEl566SWEhYU5YioqKrBkyRLs3r0bgYGBmD9/PrKyshy/o3v27MHkyZPbtX3q1CmYzWbV/Xfb5ElERN3n7skzJSUFp06dQm5uLux2OxYuXIi0tDRkZ2d3+pzly5dj586d2L59O0wmEzIyMjBnzhx89tlnAIALFy5g5syZMJvN+Pzzz3Hq1Cn85je/gY+PD/7nf/7Hqa2ysjKn+umhoaGi/jN5EhHRFVVaWoqcnBwcOHAAY8eOBQC88MILmDFjBp5++mlERES0e47VasWrr76K7OxsTJkyBQCwefNmxMTEYN++fZgwYQI++eQTHDlyBLt27UJYWBjGjBmDxx57DA888ADWrFkDg8HgaC80NBRBQUHd3gZ+50lEpENtI8+e3ADAZrM53aRXeOpIYWEhgoKCHIkTABITE+Hp6YmioqIOn1NcXAy73Y7ExETHfdHR0Rg0aBAKCwsd7d54441O07hJSUmw2Ww4fPiwU3tjxoxBeHg4fvGLXzhGrhJMnkREOuSq5BkZGQmTyeS4ZWVl9bhvFoul3TSpt7c3goODYbFYOn2OwWBoN1oMCwtzPMdisTglzrbH2x4DgPDwcGzatAnvvPMO3nnnHURGRmLSpEn48ssvRdvAaVsiIh1y1Xeex48fd/pusKvFbitXrsSTTz7ZZbulpaXd7pMrjBgxAiNGjHD8/POf/xzHjh3DunXr8Le//U11O0yeRETUKaPR6JQ8u7JixQosWLCgy5ihQ4fCbDa3Wy3d0tKC6urqTle8ms1mNDc3o6amxmn0WVVV5XiO2WzG/v37nZ5XVVXleKwz48ePx6efftplvy/F5ElEpEO9sdo2JCQEISEhl42Lj49HTU0NiouLERsbCwDIz89Ha2sr4uLiOnxObGwsfHx8kJeXh+TkZAAXV8xWVFQgPj7e0e4TTzyB06dPO6aFc3NzYTQaMXLkyE77U1JSgvDwcNG2MnkSEemQO5+qEhMTg2nTpmHRokXYtGkT7HY7MjIyMG/ePMdK25MnTyIhIQGvv/46xo8fD5PJhNTUVGRmZiI4OBhGoxFLly5FfHw8JkyYAACYOnUqRo4cif/+7//G2rVrYbFY8OCDDyI9Pd0x3fzcc88hKioK119/PRobG/HKK68gPz8fn3zyiWgbmDyJiOiK27p1KzIyMpCQkOAokrB+/XrH43a7HWVlZTh//rzjvnXr1jlif1wkoY2Xlxd27NiBJUuWID4+Hn369MH8+fPx6KOPOmKam5uxYsUKnDx5EgEBARg1ahR27drVYeGErngoblbA0GazwWQy4dtvv0Xfvn1VPUfLCkOSKkD+/v6atS2tMCTZJ1ofAlpWGJKQVhhqaWlRHfvj88fU0LLC0MCBA0XxWlYYksRfrRWGJL8/tbW1GDZsGKxWq+rvEaXaPkPfffdd9OnTp9vt1NfXY86cOZr29WrGkScRkQ6587StHrht8vTw8FA9UpCMsqSjD8lfrNL6ppJ4yShVSrL/APkoS0Iy2gMAHx8f1bFqZzLaSE4Gl/QDuFhGTItYADhx4oQoXvIhKR15SkbN0vdeMnqXHuOSxSOVlZWitkkf3DZ5EhFR93HkqS0mTyIinWIC1A7L8xEREQlx5ElEpEOcttUWkycRkQ4xeWqLyZOISIeYPLXF7zyJiIiEOPIkItIhjjy1xeRJRKRDTJ7a4rQtERGREEeeREQ6xJGnttw2eXp5eamuKxsTE6O63W+++UbUD0nN0h9fOkcNSd1caU1eyRVepHVz7Xa7Zn2RXkFEUve1pqZG1LaEtN+SWqvSmsnSGrGS41DadlBQkOpYLes3S+sxV1VVadIP6dVdeoLJU1uctiUiIhISJ8+9e/fi9ttvR0REBDw8PPD+++87Pa4oCh5++GGEh4fD398fiYmJ+O6771zVXyIiUqFt5NmTG3VOnDzr6+sxevRobNiwocPH165di/Xr12PTpk0oKipCnz59kJSUpOmUDBEROWPy1Jb4O8/p06dj+vTpHT6mKAqee+45PPjgg5g1axYA4PXXX0dYWBjef/99zJs3r2e9JSIicgMu/c6zvLwcFosFiYmJjvtMJhPi4uJQWFjY4XOamppgs9mcbkRE1DMceWrLpcnTYrEAAMLCwpzuDwsLczx2qaysLJhMJsctMjLSlV0iIvpJYvLUVq+vtl21ahWsVqvjdvz48d7uEhHRVY/JU1suTZ5msxlA+3OkqqqqHI9dytfXF0aj0elGRETkzlyaPKOiomA2m5GXl+e4z2azoaioCPHx8a58KSIi6gJHntoSr7atq6vD0aNHHT+Xl5ejpKQEwcHBGDRoEJYtW4bHH38cw4cPR1RUFB566CFERERg9uzZruw3ERF1gRWGtCVOnl988QUmT57s+DkzMxMAMH/+fGzZsgX3338/6uvrkZaWhpqaGtxyyy3IycmBn5+f6HXsdrvqMnCHDx9W3a70gGhqalIdKy2hp2WpLkm5uICAAM3alsZL94mkfOKlC9kup7KyUnWsr6+vqO26ujrVsdLSctISepKvSmpra0Vt19fXi+IlJKUZJbGA7HNC8nsv7Qe5L3HynDRpUpcHloeHBx599FE8+uijPeoYERF1H0ee2nLbwvBERNR9TJ7a6vVTVYiIiK42HHkSEekQR57aYvIkItIhJk9tcdqWiIhIiCNPIiKd4uhRO0yeREQ6xGlbbTF5EhHpEJOntvidJxERkRBHnkREOsSRp7bcNnn6+Piorlvq6al+AN3c3NzdLrm0H4C2tTm1rJvb2toqipfUn5X+wqqtfwxcvIiBhKRGbGhoqKjtkydPqo6VbCMgPw7Pnz+vWV/69++vOtZms4nalvD39xfFNzY2qo6V/G5Kf3d6gslTW5y2JSIiEnLbkScREXUfR57aYvIkItIhJk9tcdqWiIhIiCNPIiId4shTWxx5EhHpUFvy7MlNS9XV1UhJSYHRaERQUBBSU1NRV1fX5XMaGxuRnp6O/v37IzAwEMnJyaiqqnKK+d3vfofY2Fj4+vpizJgxHbZz8OBB3HrrrfDz80NkZCTWrl0r7j+TJxGRDrl78kxJScHhw4eRm5uLHTt2YO/evUhLS+vyOcuXL8eHH36I7du3o6CgAJWVlZgzZ067uLvvvhtz587tsA2bzYapU6di8ODBKC4uxlNPPYU1a9bg5ZdfFvWf07ZERHRFlZaWIicnBwcOHMDYsWMBAC+88AJmzJiBp59+GhEREe2eY7Va8eqrryI7OxtTpkwBAGzevBkxMTHYt28fJkyYAABYv349AODMmTM4ePBgu3a2bt2K5uZm/PWvf4XBYMD111+PkpISPPvss5dN3j/GkScRkQ65auRps9mcbk1NTT3uW2FhIYKCghyJEwASExPh6emJoqKiDp9TXFwMu92OxMREx33R0dEYNGgQCgsLRa89ceJEGAwGx31JSUkoKyvDf/7zH9XtMHkSEemQq5JnZGQkTCaT45aVldXjvlkslnZVuby9vREcHAyLxdLpcwwGA4KCgpzuDwsL6/Q5nbUTFhbWro22x9Ry22nblpYW1eXRJCWv/Pz8RP2QlOmSlKGTth0QECBqW7JPpCULpdspaV9aWk5C2m9Jeb7Tp0+L2vb19VUd29DQIGpbWgLObDarjq2srBS1LSm5ZzKZRG1L9rmkBCEgOw61inUXx48fh9FodPzc1bG7cuVKPPnkk122V1pa6rK+9Sa3TZ5ERNR9rjpVxWg0OiXPrqxYsQILFizoMmbo0KEwm83t/vhpaWlBdXV1p3/Mmc1mNDc3o6amxmn0WVVVJfoD0Gw2t1uh2/azpB0mTyIiHeqN8zxDQkIQEhJy2bj4+HjU1NSguLgYsbGxAID8/Hy0trYiLi6uw+fExsbCx8cHeXl5SE5OBgCUlZWhoqIC8fHxqvsYHx+PP/7xj7Db7Y7ZqNzcXIwYMQL9+vVT3c7VN4dARERXtZiYGEybNg2LFi3C/v378dlnnyEjIwPz5s1zrLQ9efIkoqOjsX//fgAXp/VTU1ORmZmJ3bt3o7i4GAsXLkR8fLxjpS0AHD16FCUlJbBYLGhoaEBJSQlKSkocXx/dddddMBgMSE1NxeHDh7Ft2zY8//zzyMzMFG0DR55ERDrk7hWGtm7dioyMDCQkJMDT0xPJycmO00yAi5e/Kysrc/q+et26dY7YpqYmJCUl4aWXXnJq95577kFBQYHj55/97GcALl6ScMiQITCZTPjkk0+Qnp6O2NhYDBgwAA8//LDoNBWAyZOISJfcPXkGBwcjOzu708eHDBnSrg9+fn7YsGEDNmzY0Onz9uzZc9nXHjVqFP73f/9XdV87wmlbIiIiIY48iYh0yN1Hnlc7Jk8iIh1i8tQWkycRkU4xAWqH33kSEREJceRJRKRDnLbVltsmTy8vL3h5eamKldQgtdvt3e3SZUlrxEZHR6uOLSsrE7UtOfCl9X6lJH2R1mWV1KuVXg1C0nb//v1FbUtqvv746g9qSI/DkydPqo5V+zvZRlK/+dy5c6K2JXVipce4pJ6w5P2R7r+eYPLUFqdtiYiIhNx25ElERN3Hkae2mDyJiHSIyVNbnLYlIiIS4siTiEiHOPLUFpMnEZEOMXlqi9O2REREQhx5EhHpEEee2mLyJCLSISZPbTF5EhHpEJOnttw2eRoMBvj6+qqKlZTekpZok5TekpaWq6ioUB17/vx5Udv+/v6qYyWlyAD5L1VwcLDq2OrqalHboaGhqmMlZegAWSm1qqoqUdsXLlxQHSspQ9cd3t7qPwYk5fYA2e+PtHSm2s8HQLa/AVm/mWR+mtw2eRIRUfdx5KktJk8iIh1i8tSWeD5o7969uP322xEREQEPDw+8//77To8vWLAAHh4eTrdp06a5qr9ERES9TjzyrK+vx+jRo3H33Xdjzpw5HcZMmzYNmzdvdvws+W6CiIh6jiNPbYmT5/Tp0zF9+vQuY3x9fWE2m7vdKSIi6hkmT21psoxvz549CA0NxYgRI7BkyZIuL3Lb1NQEm83mdCMiInJnLk+e06ZNw+uvv468vDw8+eSTKCgowPTp0ztdKp6VlQWTyeS4RUZGurpLREQ/OW0jz57cqHMuX207b948x/9vvPFGjBo1Ctdeey327NmDhISEdvGrVq1CZmam42ebzcYESkTUQ5y21ZbmheGHDh2KAQMG4OjRox0+7uvrC6PR6HQjIiJyZ5qf53nixAmcO3cO4eHhWr8UERH9H448tSVOnnV1dU6jyPLycpSUlCA4OBjBwcF45JFHkJycDLPZjGPHjuH+++/HsGHDkJSU5NKOExFR55g8tSVOnl988QUmT57s+Lnt+8r58+dj48aNOHjwIF577TXU1NQgIiICU6dOxWOPPSY+17O+vl51TU8PDw/V7UpiAdkBJKmHKW1buv8k9WoDAgJEbUvrm9bU1KiO9fHxEbUtqcsaEhIiavs///mP6ljpB42W9Wql+1BSw1d6HFqtVtWx0n0i+V2W1raVkLTd0tKiWT86wgSoHXHynDRpUpdvyMcff9yjDhEREbk71rYlItIhTttqi8mTiEiHmDy1pfmpKkRERHrDkScRkQ5x5KktJk8iIh1i8tQWp22JiIiEOPIkItIhjjy1xeRJRKRDTJ7a4rQtERGREEeeREQ6xJGnttw2eRoMBtW1YiX1Iv38/ET9aG5uVh0rrVspiZfW5JXUCZXW/ZTUkwVkv4TS96eqqkp17NmzZ0VtX3PNNapjLRaLqG1JPVnJMQjIa9tK2pceK/7+/qpj7Xa7qG1JvJa1hyX7RMsau5di8tQWp22JiHSoLXn25Kal6upqpKSkwGg0IigoCKmpqairq+vyOY2NjUhPT0f//v0RGBiI5OTkdn9A/+53v0NsbCx8fX0xZsyYdm18//338PDwaHfbt2+fqP9MnkREdMWlpKTg8OHDyM3NxY4dO7B3716kpaV1+Zzly5fjww8/xPbt21FQUIDKykrMmTOnXdzdd9+NuXPndtnWrl27cOrUKcctNjZW1H+3nbYlIqLuc9W0rc1mc7rf19dXfGm6S5WWliInJwcHDhzA2LFjAQAvvPACZsyYgaeffhoRERHtnmO1WvHqq68iOzsbU6ZMAQBs3rwZMTEx2LdvHyZMmAAAWL9+PQDgzJkzOHjwYKd96N+/P8xmc7e3gSNPIiIdctW0bWRkJEwmk+OWlZXV474VFhYiKCjIkTgBIDExEZ6enigqKurwOcXFxbDb7UhMTHTcFx0djUGDBqGwsFDch1/96lcIDQ3FLbfcgn/84x/i53PkSUREnTp+/DiMRqPj556OOoGLC+xCQ0Od7vP29kZwcHCni+8sFgsMBgOCgoKc7g8LCxMt2AsMDMQzzzyDm2++GZ6ennjnnXcwe/ZsvP/++/jVr36luh0mTyIiHXLVtK3RaHRKnl1ZuXIlnnzyyS5jSktLu90nVxgwYAAyMzMdP48bNw6VlZV46qmnmDyJiH7qeuNUlRUrVmDBggVdxgwdOhRmsxmnT592ur+lpQXV1dWdfg9pNpvR3NyMmpoap9FnVVVVj767BIC4uDjk5uaKnsPkSURELhESEoKQkJDLxsXHx6OmpgbFxcWOVa75+flobW1FXFxch8+JjY2Fj48P8vLykJycDAAoKytDRUUF4uPje9TvkpIShIeHi57D5ElEpEPuXCQhJiYG06ZNw6JFi7Bp0ybY7XZkZGRg3rx5jpW2J0+eREJCAl5//XWMHz8eJpMJqampyMzMRHBwMIxGI5YuXYr4+HjHSlsAOHr0KOrq6mCxWNDQ0ICSkhIAwMiRI2EwGPDaa6/BYDDgZz/7GQDg3XffxV//+le88sorom1g8iQi0iF3Tp4AsHXrVmRkZCAhIQGenp5ITk52nGYCXKwgVVZWhvPnzzvuW7dunSO2qakJSUlJeOmll5zaveeee1BQUOD4uS1JlpeXY8iQIQCAxx57DD/88AO8vb0RHR2Nbdu24Y477hD130NxsxpMNpsNJpMJ5eXlqr+klpbFk5DsHmnpLck0waXfD1xOa2ur6lhJKTIAqssmdqcv0tJ/gwYNUh37zTffiNqW7BfJNgKy8nzS41ta4rCxsVF1rPRY0bJMZN++fVXHSt8fyT6X7L/a2lpER0fDarWq/nyTavsMXbJkSY9WxjY1NWHjxo2a9vVqxpEnEZEOufvI82rH5ElEpENMntpi8iQi0ikmQO2wPB8REZEQR55ERDrEaVttMXkSEekQk6e2OG1LREQkxJEnEZEOceSpLSZPIiIdYvLUFqdtiYiIhDjyJCLSIY48teW2ydNut6O5uVlVrKRupZZ1P/39/UVtS65+HhAQIGpbsk+kvyTSeLvdrjpWWt/0u+++Ux07cOBAUds//PCD6lhpvV9JzdGGhgZR29J9KKmzq2Vt2+DgYFHbknrPkm0EZP2W1GOW1m7uCSZPbXHaloiISMhtR55ERNR9HHlqi8mTiEiHmDy1xeRJRKRDTJ7a4neeREREQhx5EhHpEEee2mLyJCLSISZPbXHaloiISIgjTyIiHeLIU1tMnkREOsTkqS1O2xIREQlx5ElEpEMceWqLyZOISIeYPLUlmrbNysrCuHHj0LdvX4SGhmL27NkoKytzimlsbER6ejr69++PwMBAJCcno6qqyqWdJiIi6k2i5FlQUID09HTs27cPubm5sNvtmDp1Kurr6x0xy5cvx4cffojt27ejoKAAlZWVmDNnjss7TkREnWsbefbkRp0TTdvm5OQ4/bxlyxaEhoaiuLgYEydOhNVqxauvvors7GxMmTIFALB582bExMRg3759mDBhQrs2m5qa0NTU5PjZZrN1ZzuIiOhHOG2rrR6ttrVarQD+/0Vsi4uLYbfbkZiY6IiJjo7GoEGDUFhY2GEbWVlZMJlMjltkZGRPukRERP+Ho07tdDt5tra2YtmyZbj55ptxww03AAAsFgsMBgOCgoKcYsPCwmCxWDpsZ9WqVbBarY7b8ePHu9slIiKiK6Lbq23T09Nx6NAhfPrppz3qgK+vL3x9fXvUBhEROeO0rba6lTwzMjKwY8cO7N27FwMHDnTcbzab0dzcjJqaGqfRZ1VVFcxmc487S0RE6jB5aks0basoCjIyMvDee+8hPz8fUVFRTo/HxsbCx8cHeXl5jvvKyspQUVGB+Ph41/SYiIiol4lGnunp6cjOzsYHH3yAvn37Or7HNJlM8Pf3h8lkQmpqKjIzMxEcHAyj0YilS5ciPj6+w5W2RESkDY48tSVKnhs3bgQATJo0yen+zZs3Y8GCBQCAdevWwdPTE8nJyWhqakJSUhJeeuklccckb7yXl5fqdltaWkT98PHxUR1rt9s1a7u1tVXUtre3+rdW2u/m5mZRvIR0OyX7sLa2VtR2TU2N6lhpvyV9kRzfAHDhwgVR/KhRo1THVlRUiNpuW5Gvxrlz50RtGwwG1bHSfSKNV0t6nPQEk6e2RMlTzc708/PDhg0bsGHDhm53ioiIyJ2xti0RkQ5x5KktJk8iIh1i8tQWr+dJREQkxJEnEZEOceSpLSZPIiIdYvLUFqdtiYh0yN0vSVZdXY2UlBQYjUYEBQUhNTUVdXV1XT7ncteL/vrrr3HnnXciMjIS/v7+iImJwfPPP9+unT179uCmm26Cr68vhg0bhi1btoj7z+RJRERXXEpKCg4fPozc3FxHude0tLQun3O560UXFxcjNDQUb7zxBg4fPow//vGPWLVqFV588UVHTHl5OWbOnInJkyejpKQEy5Ytwz333IOPP/5Y1H8Pxc3G5jabDSaTCWVlZejbt6+q53h6qv8bwMPDQ9QfSbx0V0r6LT1R/motkiAlKZIQGBgoaltSJEHyXgKyYh0/lSIJ0t9NyX6R7hOtPhZra2tx3XXXwWq1wmg0avIabZ+hv/zlL0W/H5ey2+3YsWOHJn0tLS3FyJEjceDAAYwdOxbAxetFz5gxAydOnEBERES751itVoSEhCA7Oxt33HEHAOCbb75BTEwMCgsLO61il56ejtLSUuTn5wMAHnjgAezcuROHDh1yxMybNw81NTXtrlndFY48iYh0yFXTtjabzenW1NTU474VFhYiKCjIkTgBIDExEZ6enigqKurwOd25XjRwMem2XXO67bV/3AYAJCUlddlGR9x2wZC3t7fq0ZPkr3hJSS9A9heotPSWpG3paE+yT7QcjUvjpSMEyT6XjIIA2fsjHdU2NjZq0g9ANusAyEaTP/4QUuPUqVOqY6UfypJjXDozIDmutJz5cgeRkZFOP69evRpr1qzpUZsWiwWhoaFO93l7eyM4OLjTaz9353rRn3/+ObZt24adO3c6tRMWFtauDZvNhoaGBvj7+6vaBrdNnkRE1H2uWm17/Phxp2nbrq6/vHLlSjz55JNdtltaWtrtPkkcOnQIs2bNwurVqzF16lSXt8/kSUSkQ65KnkajUfV3nitWrHBcJKQzQ4cOhdlsxunTp53ub2lpQXV1dafXfpZcL/rIkSNISEhAWloaHnzwwXbt/HiFblsbRqNR9agTYPIkIiIXCQkJQUhIyGXj4uPjUVNTg+LiYsTGxgIA8vPz0drairi4uA6f8+PrRScnJwPo+HrRhw8fxpQpUzB//nw88cQTHb72Rx995HRfbm6u+JrTXDBERKRD7nyeZ0xMDKZNm4ZFixZh//79+Oyzz5CRkYF58+Y5VtqePHkS0dHR2L9/PwA4XS969+7dKC4uxsKFC52uF33o0CFMnjwZU6dORWZmJiwWCywWC86cOeN47cWLF+Pf//437r//fnzzzTd46aWX8Pbbb2P58uWibWDyJCLSIXdOngCwdetWREdHIyEhATNmzMAtt9yCl19+2fG43W5HWVkZzp8/77hv3bp1+OUvf4nk5GRMnDgRZrMZ7777ruPxv//97zhz5gzeeOMNhIeHO27jxo1zxERFRWHnzp3Izc3F6NGj8cwzz+CVV15BUlKSqP9ue57nsWPHVJ/n6S6rbaUrRSWr9KQrebVcASjdTi1X20pWlkoPdck+N5lMora1XG0rJfmex51W20r2i3S1reQ4lLRdW1uL4cOHX5HzPJOSknp8nufHH3+saV+vZvzOk4hIh1jbVltMnkREOsTkqS0mTyIiHWLy1BYXDBEREQlx5ElEpFMcPWrHbZPnhQsXVK94kxwg0pWlkhWAklWLgGzFZUBAgKhtyUpRLa8GA8jq8kqvIKLley9p+8fL6dXoqsTZpRoaGkRtS9lsNtWx0quqSFatSq7uAgBfffWV6ljpe6/VKu4rWduW07ba4rQtERGRkNuOPImIqPs48tQWkycRkQ4xeWqL07ZERERCHHkSEekQR57aYvIkItIhJk9tcdqWiIhIiCNPIiId4shTW0yeREQ6xOSpLSZPIiIdYvLUltsmT4PBoLqEmeRNlpSKAwA/Pz/VsZKLcgOycn6SUn6AthfaHjx4sCi+srJSdax0OyXl/KRlBbV8fyTHobTf0g89SalA6bEi+Z0oKSkRtd2nTx/VsZJye4Cs3KKWpTDJfblt8iQiou7jyFNbTJ5ERDrE5KktnqpCREQkxJEnEZEOceSpLSZPIiIdYvLUFqdtiYiIhDjyJCLSIY48tcXkSUSkQ0ye2uK0LRERkRBHnkREOsSRp7aYPImIdIjJU1tumzwlb7ykTqikjiegbd1KDw8PTfoBABcuXNCkHwBw4sQJUbykfR8fH1Hbkvqm9fX1orYl+1xSB1fatt1uF7UdEBAgijcajapjz507J2pbsp3S47ChoUEULyGpJyz5vb+SCYnJU1v8zpOIiEhIlDyzsrIwbtw49O3bF6GhoZg9ezbKysqcYiZNmgQPDw+n2+LFi13aaSIiury20Wd3btQ1UfIsKChAeno69u3bh9zcXNjtdkydOrXddNiiRYtw6tQpx23t2rUu7TQREXWtJ4mTCfTyRN955uTkOP28ZcsWhIaGori4GBMnTnTcHxAQALPZ7JoeEhERuZkefedptVoBAMHBwU73b926FQMGDMANN9yAVatWdXlh2aamJthsNqcbERH1DEee2ur2atvW1lYsW7YMN998M2644QbH/XfddRcGDx6MiIgIHDx4EA888ADKysrw7rvvdthOVlYWHnnkke52g4iIOsDVttrqdvJMT0/HoUOH8Omnnzrdn5aW5vj/jTfeiPDwcCQkJODYsWO49tpr27WzatUqZGZmOn622WyIjIzsbreIiIg0163kmZGRgR07dmDv3r0YOHBgl7FxcXEAgKNHj3aYPH19fcXnXhIRUdc48tSWKHkqioKlS5fivffew549exAVFXXZ55SUlAAAwsPDu9VBIiKSY/LUlih5pqenIzs7Gx988AH69u0Li8UCADCZTPD398exY8eQnZ2NGTNmoH///jh48CCWL1+OiRMnYtSoUZpsABER0ZUmSp4bN24EcLEQwo9t3rwZCxYsgMFgwK5du/Dcc8+hvr4ekZGRSE5OxoMPPuiyDhMR0eVx5Kkt8bRtVyIjI1FQUNCjDrVpaWlRXdPT21v9Zkjq4AKyGpdeXl6itiV9kdZOldS2HTBggKjtqqoqUbykvqlkfwOyfS7dh42NjapjW1paRG1L3h9JLCD/0Dt79qxmbUtI6hQD2ta2lWyn5JiVHt89weSpLbctDE9ERN3H5KktFoYnIqIrrrq6GikpKTAajQgKCkJqairq6uq6fE5jYyPS09PRv39/BAYGIjk52Wkm7Ouvv8add96JyMhI+Pv7IyYmBs8//7xTG3v27GlXf93Dw8OxhkctjjyJiHTI3UeeKSkpOHXqlKNO+sKFC5GWlobs7OxOn7N8+XLs3LkT27dvh8lkQkZGBubMmYPPPvsMAFBcXIzQ0FC88cYbiIyMxOeff460tDR4eXkhIyPDqa2ysjKny/GFhoaK+s/kSUSkQ+6cPEtLS5GTk4MDBw5g7NixAIAXXngBM2bMwNNPP42IiIh2z7FarXj11VeRnZ2NKVOmALi4WDUmJgb79u3DhAkTcPfddzs9Z+jQoSgsLMS7777bLnmGhoYiKCio29vAaVsiIurUpbXHm5qaetxmYWEhgoKCHIkTABITE+Hp6YmioqIOn1NcXAy73Y7ExETHfdHR0Rg0aBAKCws7fS2r1dqu/joAjBkzBuHh4fjFL37hGLlKMHkSEemQqwrDR0ZGwmQyOW5ZWVk97pvFYmk3Tert7Y3g4OBOv3u0WCwwGAztRothYWGdPufzzz/Htm3bnMrGhoeHY9OmTXjnnXfwzjvvIDIyEpMmTcKXX34p2gZO2xIR6ZCrpm2PHz/u9N1gV+VUV65ciSeffLLLdktLS7vdJ4lDhw5h1qxZWL16NaZOneq4f8SIERgxYoTj55///Oc4duwY1q1bh7/97W+q22fyJCKiThmNRqfk2ZUVK1ZgwYIFXcYMHToUZrMZp0+fdrq/paUF1dXVnV4L2mw2o7m5GTU1NU6jz6qqqnbPOXLkCBISEpCWlqaqSM/48ePbXeTkcpg8iYh0qDcWDIWEhCAkJOSycfHx8aipqUFxcTFiY2MBAPn5+WhtbXVcTORSsbGx8PHxQV5eHpKTkwFcXDFbUVGB+Ph4R9zhw4cxZcoUzJ8/H0888YSqfpeUlIjrrzN5EhHpkDuvto2JicG0adOwaNEibNq0CXa7HRkZGZg3b55jpe3JkyeRkJCA119/HePHj4fJZEJqaioyMzMRHBwMo9GIpUuXIj4+HhMmTABwcap2ypQpSEpKQmZmpuO7UC8vL0dSf+655xAVFYXrr78ejY2NeOWVV5Cfn49PPvlEtA1umzy9vb3h4+OjKlZS5k56+TNJaTlpGbWOLtHWmW+//VbUtuTAr6ysFLWtZQk9LcvcScu5Sfqt9lhtIzmu1JapbCMtQ2i1WlXHBgQEiNqWqK+vF8V7eHho1BPZMS45BiXvu95t3boVGRkZSEhIgKenJ5KTk7F+/XrH43a7HWVlZTh//rzjvnXr1jlim5qakJSUhJdeesnx+N///necOXMGb7zxBt544w3H/YMHD8b3338P4GK+WLFiBU6ePImAgACMGjUKu3btwuTJk0X991DcrAaTzWaDyWRCeXm56nl2Js/2JG+r9ENImii0TJ6SeqjSD2dJv6V1jX8qyVNyWoP0OLwak2dtbS2uu+46WK1W1Z9vUm2focOGDRMflz924cIFHD16VNO+Xs3cduRJRETd587TtnrA5ElEpENMntpikQQiIiIhjjyJiHSKo0ftMHkSEekQp221xWlbIiIiIY48iYh0iCNPbTF5EhHpEJOntjhtS0REJMSRJxGRDnHkqS23TZ6KoqguYda/f3/V7VZXV4v64efnpzpWUiYQuFj4WK3GxkZR2waDQXWs9Mrw0nJxkZGRqmPLy8tFbdtsNlG8hKTsmvSDRtK25L0EgLq6OlG8pMShtDart7f6jxhp25IyhNK2JWUiJeUqpaUte4LJU1uctiUiIhJy25EnERF1H0ee2mLyJCLSISZPbTF5EhHpEJOntvidJxERkRBHnkREOsSRp7aYPImIdIjJU1uctiUiIhLiyJOISIc48tQWkycRkQ4xeWpLF8lTUnJPUi4MkJWik5Rck5K2LSkVKC3/Ji3P9+9//1sULyEpd+bpKfuWQssPD0lJRGk/Bg8eLIqvqqpSHSsp5QfIyidKt1NyHErK7QGyY0V6XJE+6CJ5EhGRM448tcXkSUSkQ0ye2uJ8AxERkRBHnkREOsSRp7aYPImIdIjJU1tMnkREOsTkqS1+50lERCTEkScRkU5x9KgdJk8iIh3qaeJk4u0ap22JiIiEOPIkItIhjjy15bbJMzo6Gh4eHqpi6+vrVbdbU1Mj6oeXl5fqWD8/P1Hbktqc0vqZAQEBqmPr6upEbUt/qSR9kbyXgKyGr9rjqY3kvZfWTtXyg+n7778XxUv2i6SONCD7nZC8l4Cs35L3Utq2uyYZJk9tcdqWiIhISJQ8N27ciFGjRsFoNMJoNCI+Ph7//Oc/HY83NjYiPT0d/fv3R2BgIJKTk0VXbCAiItdoO8+zJzfqnCh5Dhw4EH/6059QXFyML774AlOmTMGsWbNw+PBhAMDy5cvx4YcfYvv27SgoKEBlZSXmzJmjSceJiKhzTJ7aEn3nefvttzv9/MQTT2Djxo3Yt28fBg4ciFdffRXZ2dmYMmUKAGDz5s2IiYnBvn37MGHCBNf1moiIqBd1+zvPCxcu4K233kJ9fT3i4+NRXFwMu92OxMRER0x0dDQGDRqEwsLCTttpamqCzWZzuhERUc9w5KktcfL817/+hcDAQPj6+mLx4sV47733MHLkSFgsFhgMBgQFBTnFh4WFwWKxdNpeVlYWTCaT4xYZGSneCCIicsbkqS1x8hwxYgRKSkpQVFSEJUuWYP78+Thy5Ei3O7Bq1SpYrVbH7fjx491ui4iILmLy1Jb4PE+DwYBhw4YBAGJjY3HgwAE8//zzmDt3Lpqbm1FTU+M0+qyqqoLZbO60PV9fX/j6+sp7TkRE1Et6fJ5na2srmpqaEBsbCx8fH+Tl5TkeKysrQ0VFBeLj43v6MkREJODuI8/q6mqkpKTAaDQiKCgIqamply3YcrnTIc+dO4dp06YhIiICvr6+iIyMREZGRru1NHv27MFNN90EX19fDBs2DFu2bBH3X5Q8V61ahb179+L777/Hv/71L6xatQp79uxBSkoKTCYTUlNTkZmZid27d6O4uBgLFy5EfHw8V9oSEV1h7p48U1JScPjwYeTm5mLHjh3Yu3cv0tLSunzO5U6H9PT0xKxZs/CPf/wD3377LbZs2YJdu3Zh8eLFjpjy8nLMnDkTkydPRklJCZYtW4Z77rkHH3/8saj/HopgD6WmpiIvLw+nTp2CyWTCqFGj8MADD+AXv/gFgIt/FaxYsQJvvvkmmpqakJSUhJdeeqnLadtL2Ww2mEwm9O3bV3WJrO+++051+9IDQlKmS1r+zdtb/ax5Q0ODqG1pXySkpQIl0/LSMnda7kNJ2waDQdR2Y2Oj6lhpaTlpvGSfS98fLUnKPvr7+4valqz6v3DhgurY2tpaDB8+HFarFUajUdQntdo+Q319fXv0OaAoCpqamjTpa2lpKUaOHIkDBw5g7NixAICcnBzMmDEDJ06cQERERLvnWK1WhISEIDs7G3fccQcA4JtvvkFMTAwKCws7HaStX78eTz31lGM9zQMPPICdO3fi0KFDjph58+ahpqYGOTk5qrdB9J3nq6++2uXjfn5+2LBhAzZs2CBploiIXMxVtW0v/UPCFetUCgsLERQU5EicAJCYmAhPT08UFRXh17/+dbvnXO50yI6SZ2VlJd59913cdtttTq/94zYAICkpCcuWLRNtA2vbEhHpkKumbSMjI51OJ8zKyupx3ywWC0JDQ53u8/b2RnBwcKenNkpOh7zzzjsREBCAa665BkajEa+88opTO2FhYe3asNlsotkpJk8iIurU8ePHnU4nXLVqVaexK1euhIeHR5e3b775RvM+r1u3Dl9++SU++OADHDt2DJmZmS5/Dbe9JBkREXWfq6Zt2y4EosaKFSuwYMGCLmOGDh0Ks9mM06dPO93f0tKC6urqTtfImM1m1adDms1mmM1mREdHIzg4GLfeeiseeughhIeHw2w2t7tgSVVVFYxGo+i7cSZPIiIdclXylAgJCUFISMhl4+Lj41FTU4Pi4mLExsYCAPLz89Ha2oq4uLgOn/Pj0yGTk5MBqDsdsrW1FcDFUrBtr/3RRx85xeTm5opPqWTyJCKiKyomJgbTpk3DokWLsGnTJtjtdmRkZGDevHmOlbYnT55EQkICXn/9dYwfP97pdMjg4GAYjUYsXbrU6XTIjz76CFVVVRg3bhwCAwNx+PBh/P73v8fNN9+MIUOGAAAWL16MF198Effffz/uvvtu5Ofn4+2338bOnTtF28DkSUSkQ70x8pTYunUrMjIykJCQAE9PTyQnJ2P9+vWOx+12O8rKynD+/HnHfevWrXPE/vh0yDb+/v74y1/+guXLl6OpqQmRkZGYM2cOVq5c6YiJiorCzp07sXz5cjz//PMYOHAgXnnlFSQlJYn6LzrP80rgeZ4d43meHeN5nj2P53me7enhPM+2BTrd1bbiVsu+Xs048iQi0iF3H3le7XiqChERkZDbjTzb/tqR/NVTW1srbl8tLadtJdNrkmm+7vRFQjpt27bKTQ3JFBig7T6UTNv6+PiI2pbsE+k0rPT9kexzd5q2lfTFbreL2pZ8pkinbYErN6rj6FE7bpc82w6uy1XX/7G2S6QREV0NamtrYTKZNGnbYDDAbDZ3WqlHwmw2i7/P/6lwuwVDra2tqKysbLdgyGazITIyEsePH9f1l9fcTv34KWwjwO2UUBQFtbW1iIiIEM8QSDQ2NqK5ubnH7RgMBvj5+bmgR/rjdiNPT09PDBw4sNPHJdUurmbcTv34KWwjwO1US6sR54/5+fkx6WmMC4aIiIiEmDyJiIiErprk6evri9WrV/f4OnLujtupHz+FbQS4nfTT5HYLhoiIiNzdVTPyJCIichdMnkREREJMnkREREJMnkREREJMnkREREJXTfLcsGEDhgwZAj8/P8TFxWH//v293SWXWrNmjeP6e2236Ojo3u5Wj+zduxe33347IiIi4OHhgffff9/pcUVR8PDDDyM8PBz+/v5ITEwUXZvVXVxuOxcsWNDuvZ02bVrvdLabsrKyMG7cOPTt2xehoaGYPXs2ysrKnGIaGxuRnp6O/v37IzAwEMnJyaiqquqlHnePmu2cNGlSu/dz8eLFvdRj6i1XRfLctm0bMjMzsXr1anz55ZcYPXo0kpKScPr06d7umktdf/31OHXqlOP26aef9naXeqS+vh6jR4/Ghg0bOnx87dq1WL9+PTZt2oSioiL06dMHSUlJ4quf9LbLbScATJs2zem9ffPNN69gD3uuoKAA6enp2LdvH3Jzc2G32zF16lTU19c7YpYvX44PP/wQ27dvR0FBASorKzFnzpxe7LWcmu0EgEWLFjm9n2vXru2lHlOvUa4C48ePV9LT0x0/X7hwQYmIiFCysrJ6sVeutXr1amX06NG93Q3NAFDee+89x8+tra2K2WxWnnrqKcd9NTU1iq+vr/Lmm2/2Qg9d49LtVBRFmT9/vjJr1qxe6Y9WTp8+rQBQCgoKFEW5+N75+Pgo27dvd8SUlpYqAJTCwsLe6maPXbqdiqIot912m3Lvvff2XqfILbj9yLO5uRnFxcVITEx03Ofp6YnExEQUFhb2Ys9c77vvvkNERASGDh2KlJQUVFRU9HaXNFNeXg6LxeL0vppMJsTFxenufQWAPXv2IDQ0FCNGjMCSJUtw7ty53u5Sj1itVgBAcHAwAKC4uBh2u93p/YyOjsagQYOu6vfz0u1ss3XrVgwYMAA33HADVq1ahfPnz/dG96gXud1VVS519uxZXLhwAWFhYU73h4WF4ZtvvumlXrleXFwctmzZghEjRuDUqVN45JFHcOutt+LQoUPo27dvb3fP5dquNdjR++qK6xC6k2nTpmHOnDmIiorCsWPH8Ic//AHTp09HYWGh+ELX7qC1tRXLli3DzTffjBtuuAHAxffTYDAgKCjIKfZqfj872k4AuOuuuzB48GBERETg4MGDeOCBB1BWVoZ33323F3tLV5rbJ8+fiunTpzv+P2rUKMTFxWHw4MF4++23kZqa2os9o56aN2+e4/833ngjRo0ahWuvvRZ79uxBQkJCL/ase9LT03Ho0KGr/jv5y+lsO9PS0hz/v/HGGxEeHo6EhAQcO3YM11577ZXuJvUSt5+2HTBgALy8vNqt2quqqoLZbO6lXmkvKCgI1113HY4ePdrbXdFE23v3U3tfAWDo0KEYMGDAVfneZmRkYMeOHdi9e7fTdXfNZjOam5tRU1PjFH+1vp+dbWdH4uLiAOCqfD+p+9w+eRoMBsTGxiIvL89xX2trK/Ly8hAfH9+LPdNWXV0djh07hvDw8N7uiiaioqJgNpud3lebzYaioiJdv68AcOLECZw7d+6qem8VRUFGRgbee+895OfnIyoqyunx2NhY+Pj4OL2fZWVlqKiouKrez8ttZ0dKSkoA4Kp6P8kFenvFkhpvvfWW4uvrq2zZskU5cuSIkpaWpgQFBSkWi6W3u+YyK1asUPbs2aOUl5crn332mZKYmKgMGDBAOX36dG93rdtqa2uVr776Svnqq68UAMqzzz6rfPXVV8oPP/ygKIqi/OlPf1KCgoKUDz74QDl48KAya9YsJSoqSmloaOjlnst0tZ21tbXKfffdpxQWFirl5eXKrl27lJtuukkZPny40tjY2NtdV23JkiWKyWRS9uzZo5w6dcpxO3/+vCNm8eLFyqBBg5T8/Hzliy++UOLj45X4+Phe7LXc5bbz6NGjyqOPPqp88cUXSnl5ufLBBx8oQ4cOVSZOnNjLPacr7apInoqiKC+88IIyaNAgxWAwKOPHj1f27dvX211yqblz5yrh4eGKwWBQrrnmGmXu3LnK0aNHe7tbPbJ7924FQLvb/PnzFUW5eLrKQw89pISFhSm+vr5KQkKCUlZW1rud7oautvP8+fPK1KlTlZCQEMXHx0cZPHiwsmjRoqvuD7+Otg+AsnnzZkdMQ0OD8tvf/lbp16+fEhAQoPz6179WTp061Xud7obLbWdFRYUyceJEJTg4WPH19VWGDRum/P73v1esVmvvdpyuOF7Pk4iISMjtv/MkIiJyN0yeREREQkyeREREQkyeREREQkyeREREQkyeREREQkyeREREQkyeREREQkyeREREQkyeREREQkyeREREQv8PX8oSO52kh24AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(d_logits.detach(), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('d_logits')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The black `d_logits` squares are the position of the correct indices where we substracted 1 from the gradient. The other squares are the positions where `d_logits * bs` is equal to the probability.\n",
    "\n",
    "Let's look at 1 sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:        3\n",
      "probs:    tensor([0.0169, 0.0170, 0.0293, 0.0593, 0.0290, 0.0248, 0.0547, 0.0782, 0.0586, 0.0179, 0.0154, 0.0233, 0.0286, 0.1021,\n",
      "        0.0118, 0.0096, 0.0166, 0.0185, 0.0146, 0.1269, 0.0520, 0.0301, 0.0391, 0.0276, 0.0204, 0.0548, 0.0231],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "d_logits: tensor([ 0.0169,  0.0170,  0.0293, -0.9407,  0.0290,  0.0248,  0.0547,  0.0782,  0.0586,  0.0179,  0.0154,  0.0233,\n",
      "         0.0286,  0.1021,  0.0118,  0.0096,  0.0166,  0.0185,  0.0146,  0.1269,  0.0520,  0.0301,  0.0391,  0.0276,\n",
      "         0.0204,  0.0548,  0.0231], grad_fn=<MulBackward0>)\n",
      "diff:     tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "print(f\"y:        {Yb[s]}\")\n",
    "print(f\"probs:    {F.softmax(logits, dim=1)[s]}\")\n",
    "print(f\"d_logits: {d_logits[0]*bs}\")\n",
    "print(f\"diff:     {F.softmax(logits, dim=1)[s] - d_logits[s]*bs}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`probs` sums to 1, `d_logits` sums to 0. This is logic because `d_logits` is equal to `probs` except in exactly one place where we substracted 1 . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of probs: 1.0\n",
      "sum of d_logits: -9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "print(f\"sum of probs: {F.softmax(logits, dim=1)[s].sum()}\")\n",
    "print(f\"sum of d_logits: {d_logits[s].sum()}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "The intuition is to think about the `d_logits` gradients of each sample as a force that pushes the logits up for position corresponding to the correct label and pushes the logits down for all other positions. The total amount of force is 0 because the sum of the gradients is 0.  \n",
    "The amount of force that we are applying to each position is proportional to the probability of that position. If the probabilities are exactly correct then the force that we apply to each position is 0.  The `probs` is 0 everywhere except for the correct position where it is 1. `d_logits` is 0 everywhere. If we have a confidently mispredicted element then the `probs` is ~0 everywhere except for the mispredicted position where it is ~1. `d_logits` is ~0 everywhere except for the mispredicted position where it is ~-1 and ~1 for the correct position. The force applied to the mispredicted position pulls that logit down and the equal force is applied to the correct position and pushes that logit up. \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:             3\n",
      "probs:         tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "d_logits:      tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "probs_updated: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Exacly correct\n",
    "y = 3\n",
    "print(f\"y:             {y}\")\n",
    "probs_ = torch.zeros_like(logits)\n",
    "probs_[0, y] = 1.0\n",
    "print(f\"probs:         {probs_[0]}\")\n",
    "d_logits_ = probs_.clone()\n",
    "d_logits_[0, y] -= 1.0\n",
    "print(f\"d_logits:      {d_logits_[0]}\")\n",
    "print(f\"probs_updated: {probs_[0] - d_logits_[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y:             3\n",
      "probs:         tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "d_logits:      tensor([ 1.,  0.,  0., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "         0.,  0.,  0.,  0.,  0.])\n",
      "probs_updated: tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Confidently wrong\n",
    "y = 3\n",
    "print(f\"y:             {y}\")\n",
    "probs_ = torch.zeros_like(logits)\n",
    "probs_[0, 0] = 1.0  # confident wrong predicting 0\n",
    "print(f\"probs:         {probs_[0]}\")\n",
    "d_logits_ = probs_.clone()\n",
    "d_logits_[0, y] -= 1.0\n",
    "print(f\"d_logits:      {d_logits_[0]}\")\n",
    "print(f\"probs_updated: {probs_[0] - d_logits_[0]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation through batchnorm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous sections we calculated the batchnorm in very small atomic steps and we backpropagated through each step.\n",
    "\n",
    "```python\n",
    "# batchnorm\n",
    "bn_mean_i = h_pre_bn.sum(0, keepdim=True) / bs  \n",
    "bn_diff = h_pre_bn - bn_mean_i  \n",
    "bn_diff2 = bn_diff**2  \n",
    "bn_var = bn_diff2.sum(0, keepdim=True) / (bs - 1)\n",
    "bn_var_inv = (bn_var + 1e-5) ** -0.5\n",
    "bn_raw = bn_diff * bn_var_inv  \n",
    "h_pre_act = bn_gain * bn_raw + bn_bias\n",
    "```\n",
    "\n",
    "In this section we will calculate the batchnorm in one step by using the formula $y_i=\\gamma{\\large\\frac{x_i-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}} + \\beta$ and manually backpropagate through it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "h_pre_act_fast = (\n",
    "    bn_gain\n",
    "    * (h_pre_bn - h_pre_bn.mean(0, keepdim=True))\n",
    "    / torch.sqrt(h_pre_bn.var(0, keepdim=True, unbiased=True) + 1e-5)\n",
    "    + bn_bias\n",
    ")\n",
    "print('max diff:', (h_pre_act_fast - h_pre_act).abs().max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will derive the mathematical expressions for calculating `d_h_pre_bn` in one step. \n",
    "\n",
    "```python\n",
    "h_pre_act_fast &= bn_gain*(h_pre_bn - h_pre_bn.mean(0, keepdim&=True)) / torch.sqrt(h_pre_bn.var(0, keepdim&=True, unbiased&=True) + 1e-5) + bn_bias\n",
    "```\n",
    "\n",
    "![batchnorm_diag](./media/batchnorm_diag.png)\n",
    "\n",
    "\n",
    "$\\mu = \\frac{1}{m}\\sum_{i}^{m}x_i\\\\$\n",
    "$\\sigma^2 = \\frac{1}{m-1}\\sum_{i}^{m}(x_i-\\mu)^2\\\\$\n",
    "$\\hat{x_i} = \\frac{x_i-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}\\\\$\n",
    "$y_i = \\gamma\\hat{x_i} + \\beta\\\\$\n",
    "\n",
    "We have $\\large\\frac{\\delta L}{\\delta y_1}\\\\$  \n",
    "We want $\\large\\frac{\\delta L}{\\delta x_1}\\\\$\n",
    "\n",
    "(1)\n",
    "\n",
    "\\begin{align*}\n",
    "  \\frac{\\delta L}{\\delta \\hat{x_i}} &= \\frac{\\delta L}{\\delta y_i}*\\gamma\n",
    "\\end{align*}\n",
    "\n",
    "(2)   \n",
    "The $i$ components of $\\hat x$ are dependent on $\\sigma$ in the forward pass. Therefore we have to sum over all $i$'s in the backward pass.\n",
    "  \n",
    "\\begin{align*}\n",
    "  \\frac{\\delta L}{\\delta \\sigma^2} &= \\sum_{i}\\frac{\\delta \\hat{x_i}}{\\delta \\sigma^2}\\frac{\\delta L}{\\delta \\hat{x_i}}\\\\ \n",
    "  &= \\gamma*\\sum_{i}\\frac{\\delta}{\\delta \\sigma^2}\\left[\\frac{x_i-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}\\right]\\frac{\\delta L}{\\delta y_i}\\\\\n",
    "  &= -\\frac{1}{2}*\\gamma*\\sum_{i}\\frac{\\delta}{\\delta y_i}{\\left[\\frac{x_i-\\mu}{(\\sigma^2+\\epsilon)^{\\frac{3}{2}}}\\right]}\\\\\n",
    "  \\end{align*}\n",
    "\n",
    "(3)   \n",
    "The $i$ components of $\\hat x$ are dependent on $\\mu$ in the forward pass. Therefore we have to sum over all $i$'s in the backward pass. Additionally we $\\sigma$ is dependent on $\\mu$ and therefore we also have to add the gradient of $\\sigma$ with respect to $\\mu$.\n",
    "\n",
    "\\begin{align*}\n",
    "  \\frac{\\delta L}{\\delta \\mu} &= \\sum_{i}\\frac{\\delta \\hat{x_i}}{\\delta \\mu}\\frac{\\delta L}{\\delta \\hat{x_i}} + \\frac{\\delta \\sigma^2}{\\delta \\mu}\\frac{\\delta L}{\\delta \\sigma^2}\\\\\\\\\n",
    "  \\frac{\\delta\\hat{x_i}}{\\delta \\mu} &= \\frac{\\delta}{\\delta \\mu}\\left[\\frac{x_i-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}\\right]\\\\\n",
    "  &= -\\frac{1}{\\sqrt{\\sigma^2+\\epsilon}}\\\\\\\\\n",
    "  \\frac{\\delta\\sigma^2}{\\delta \\mu} &= \\frac{\\delta}{\\delta \\mu}\\left[\\frac{1}{m-1}\\sum_{i}(x_i-\\mu)^2\\right]\\\\\n",
    "  &= \\frac{-2}{m-1}\\sum_{i}(x_i-\\mu)\\\\\\\\\n",
    "  &= \\frac{-2}{m-1}\\sum_{i}x_i -\\sum_{i}-\\mu\\\\\n",
    "  &= \\frac{-2}{m-1}\\left[m\\mu -m\\mu\\right] \\quad(\\textsf{because }\\small\\mu=\\frac{1}{m}\\sum_{i}x_i)\\\\\n",
    "  &= 0\\\\\\\\\n",
    "  \\Rightarrow  \\frac{\\delta L}{\\delta \\mu} &= -\\frac{\\gamma}{\\sqrt{\\sigma^2+\\epsilon}}\\sum_{i}\\frac{\\delta L}{\\delta y_i} + 0\\\\\n",
    "\\end{align*}\n",
    "  \n",
    "(4)\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\delta L}{\\delta x_i} &= \\frac{\\delta \\hat{x_i}}{\\delta x_i}\\frac{\\delta L}{\\delta \\hat{x_i}} + \\frac{\\delta \\mu}{\\delta x_i}\\frac{\\delta L}{\\delta \\mu} + \\frac{\\delta \\sigma^2}{\\delta x_i}\\frac{\\delta L}{\\delta \\sigma^2}\\\\\\\\\n",
    "\\frac{\\delta \\hat{x_i}}{\\delta x_i} &= \\frac{\\delta}{\\delta x_i}\\left[\\frac{x_i-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}\\right]\\\\\n",
    "&= \\frac{1}{\\sqrt{\\sigma^2+\\epsilon}}\\\\\\\\\n",
    "\\frac{\\delta \\mu}{\\delta x_i} &= \\frac{\\delta}{\\delta x_i}\\left[\\frac{1}{m}\\sum_{i}x_i\\right]\\\\\n",
    "&= \\frac{1}{m}\\\\\\\\\n",
    "\\frac{\\delta \\sigma^2}{\\delta x_i} &= \\frac{\\delta}{\\delta x_i}\\left[\\frac{1}{m-1}\\sum_{i}(x_i-\\mu)^2\\right]\\\\\n",
    "&= \\frac{2}{m-1}(x_i-\\mu)\\\\\\\\\n",
    "\n",
    "\\Rightarrow\\frac{\\delta L}{\\delta x_i} &= \\frac{1}{\\sqrt{\\sigma^2+\\epsilon}}\\frac{\\delta L}{\\delta \\hat{y_i}}*\\gamma + \\left[-\\frac{1}{m}\\frac{\\gamma}{\\sqrt{\\sigma^2+\\epsilon}}\\sum_{j}\\frac{\\delta L}{\\delta y_j}\\right] + \\left[\\frac{2}{m-1}(x_i-\\mu)\\right]\\left[-\\frac{1}{2}\\gamma\\sum_{j}\\frac{\\delta L}{\\delta y_j}\\frac{x_j-\\mu}{(\\sigma^2+\\epsilon)^{\\frac{3}{2}}}\\right]\\\\\n",
    "&= \\frac{1}{\\sqrt{\\sigma^2+\\epsilon}}\\frac{\\delta L}{\\delta \\hat{y_i}}*\\gamma - \\left[\\frac{1}{m}\\frac{\\gamma}{\\sqrt{\\sigma^2+\\epsilon}}\\sum_{j}\\frac{\\delta L}{\\delta y_j}\\right] - \\left[\\frac{1}{m-1}\\frac{x_i-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}\\right]\\left[\\frac{\\gamma}{\\sqrt{\\sigma^2+\\epsilon}}\\sum_{j}\\frac{\\delta L}{\\delta y_j}\\frac{x_j-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}\\right]\\\\\n",
    "\\left(\\textsf{because }\\small\\hat{x_i}=\\frac{x_i-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}\\right)\\\\\n",
    "&= \\frac{\\gamma}{m\\sqrt{\\sigma^2+\\epsilon}}\\left[m\\frac{\\delta L}{\\delta y_i}-\\sum_{j}\\frac{\\delta L}{\\delta y_j}-\\frac{m}{m-1}\\hat{x_i}\\sum_{j}\\frac{\\delta L}{\\delta y_j}\\hat{x_j}\\right]\\\\\n",
    "\\end{align*}\n",
    "\n",
    "The formula for $\\large\\frac{\\delta L}{\\delta x_i}$ is for a single neuron and a batch of 32 samples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_pre_bn        | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "d_h_pre_bn = (\n",
    "    bn_gain\n",
    "    * bn_var_inv\n",
    "    / bs\n",
    "    * (bs * d_h_pre_act - d_h_pre_act.sum(0) - bs / (bs - 1) * bn_raw * (d_h_pre_act * bn_raw).sum(0))\n",
    ")\n",
    "\n",
    "compare_gradients('h_pre_bn', d_h_pre_bn, h_pre_bn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the MLP model with manual backpropagation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train our MLP model with the manual backpropagation algorithm. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # parameters: 4,137\n"
     ]
    }
   ],
   "source": [
    "n_emb = 10  # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64  # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(seed)  # for reproducibility\n",
    "C = torch.randn((vocab_size, n_emb), generator=g)\n",
    "\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_emb * block_size, n_hidden), generator=g) * (5 / 3) / ((n_emb * block_size) ** 0.5)\n",
    "b1 = torch.randn(n_hidden, generator=g) * 0.1\n",
    "\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0.1\n",
    "\n",
    "# BatchNorm parameters\n",
    "bn_gain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bn_bias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bn_gain, bn_bias]\n",
    "n_params = sum(p.nelement() for p in parameters)\n",
    "print(f'Total # parameters: {n_params:,}')\n",
    "for p in parameters:\n",
    "    p.requires_grad = True\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/ 200000: 3.3884\n",
      "  10000/ 200000: 2.4541\n",
      "  20000/ 200000: 2.4857\n",
      "  30000/ 200000: 2.1198\n",
      "  40000/ 200000: 2.3114\n",
      "  50000/ 200000: 1.9466\n",
      "  60000/ 200000: 2.5517\n",
      "  70000/ 200000: 2.2360\n",
      "  80000/ 200000: 1.9703\n",
      "  90000/ 200000: 2.2679\n",
      " 100000/ 200000: 2.3220\n",
      " 110000/ 200000: 1.6446\n",
      " 120000/ 200000: 2.2917\n",
      " 130000/ 200000: 2.1344\n",
      " 140000/ 200000: 2.2928\n",
      " 150000/ 200000: 1.8781\n",
      " 160000/ 200000: 2.2685\n",
      " 170000/ 200000: 2.2070\n",
      " 180000/ 200000: 1.9090\n",
      " 190000/ 200000: 1.8184\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "bs = 32\n",
    "loss_i = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "    # kick off optimization\n",
    "    for i in range(max_steps):\n",
    "        # minibatch construct\n",
    "        ix = torch.randint(0, Xtr.shape[0], (bs,), generator=g)\n",
    "        Xb, Yb = Xtr[ix], Ytr[ix]  # batch X,Y\n",
    "\n",
    "        # forward pass\n",
    "        emb = C[Xb]  # embed the characters into vectors\n",
    "        emb_cat = emb.view(emb.shape[0], -1)  # concatenate the vectors\n",
    "        # Linear layer\n",
    "        h_pre_bn = emb_cat @ W1 + b1  # hidden layer pre-activation\n",
    "        # BatchNorm layer\n",
    "        # -------------------------------------------------------------\n",
    "        bn_mean = h_pre_bn.mean(0, keepdim=True)\n",
    "        bn_var = h_pre_bn.var(0, keepdim=True, unbiased=True)\n",
    "        bn_var_inv = (bn_var + 1e-5) ** -0.5\n",
    "        bn_raw = (h_pre_bn - bn_mean) * bn_var_inv\n",
    "        h_pre_act = bn_gain * bn_raw + bn_bias\n",
    "        # -------------------------------------------------------------\n",
    "        # Non-linearity\n",
    "        h = torch.tanh(h_pre_act)  # hidden layer\n",
    "        logits = h @ W2 + b2  # output layer\n",
    "        loss = F.cross_entropy(logits, Yb)  # loss function\n",
    "\n",
    "        # backward pass\n",
    "        for p in parameters:\n",
    "            p.grad = None\n",
    "        # loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "        # manual backprop!\n",
    "        # -----------------\n",
    "        d_logits = F.softmax(logits, 1)\n",
    "        d_logits[range(bs), Yb] -= 1\n",
    "        d_logits /= bs\n",
    "        # 2nd layer backprop\n",
    "        d_h = d_logits @ W2.T\n",
    "        d_W2 = h.T @ d_logits\n",
    "        d_b2 = d_logits.sum(0)\n",
    "        # tanh\n",
    "        d_h_pre_act = (1.0 - h**2) * d_h\n",
    "        # batchnorm backprop\n",
    "        d_bn_gain = (bn_raw * d_h_pre_act).sum(0, keepdim=True)\n",
    "        d_bn_bias = d_h_pre_act.sum(0, keepdim=True)\n",
    "        d_h_pre_bn = bn_gain * bn_var_inv / bs * (bs * d_h_pre_act - d_h_pre_act.sum(0) - bs / (bs - 1) * bn_raw * (d_h_pre_act * bn_raw).sum(0))\n",
    "        # 1st layer\n",
    "        d_emb_cat = d_h_pre_bn @ W1.T\n",
    "        d_W1 = emb_cat.T @ d_h_pre_bn\n",
    "        d_b1 = d_h_pre_bn.sum(0)\n",
    "        # embedding\n",
    "        d_emb = d_emb_cat.view(emb.shape)\n",
    "        d_C = torch.zeros_like(C)\n",
    "        for k in range(Xb.shape[0]):\n",
    "            for j in range(Xb.shape[1]):\n",
    "                ix = Xb[k, j]\n",
    "                d_C[ix] += d_emb[k, j]\n",
    "        grads = [d_C, d_W1, d_b1, d_W2, d_b2, d_bn_gain, d_bn_bias]\n",
    "        # -----------------\n",
    "\n",
    "        # update\n",
    "        lr = 0.1 if i < 100000 else 0.01  # step learning rate decay\n",
    "        for p, grad in zip(parameters, grads): # type: ignore\n",
    "            # p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "            p.data += -lr * grad  # new way of swole doge TODO: enable\n",
    "\n",
    "        # track stats\n",
    "        if i % 10000 == 0:  # print every once in a while\n",
    "            print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "        loss_i.append(loss.log10().item())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calibrate the batch norm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate train and val loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.1481568813323975\n",
      "val 2.157963275909424\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xval, Yval),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  emb_cat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  h_pre_act = emb_cat @ W1 + b1\n",
    "  h_pre_act = bn_gain * (h_pre_act - bnmean) * (bnvar + 1e-5)**-0.5 + bn_bias\n",
    "  h = torch.tanh(h_pre_act) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mora.\n",
      "kayanniee.\n",
      "madhayla.\n",
      "renyastendra.\n",
      "gradered.\n",
      "eliah.\n",
      "miloe.\n",
      "leigh.\n",
      "van.\n",
      "aar.\n",
      "kayzioh.\n",
      "kalin.\n",
      "shabergahiriel.\n",
      "kindreelynn.\n",
      "novalayubelynder.\n",
      "yah.\n",
      "fael.\n",
      "yuma.\n",
      "myston.\n",
      "azhil.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      emb_cat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      h_pre_act = emb_cat @ W1 + b1\n",
    "      h_pre_act = bn_gain * (h_pre_act - bnmean) * (bnvar + 1e-5)**-0.5 + bn_bias\n",
    "      h = torch.tanh(h_pre_act) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(ix2ch[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
